\chapter{Metodología} \label{cap2}


En este capítulo se describe a detalle la metodología utilizada en la construcción de los modelos que aquí se han propuesto para analizar los caudales de los ríos correspondientes a las 179 estaciones de medición. Se resumen las etapas de este análisis a continuación:

\begin{enumerate}

\item Realizar Análisis de Conglomerados (Clúster).
\begin{enumerate}
\item Elegir la Métrica (disimilitud). Se consideran dos métricas, y se escoge la más adecuada.
\item Elegir algoritmo de agrupamiento. En nuestro caso el algoritmo CLARA, basado en el algoritmo PAM.
\item Elegir el número de clústers.
\end{enumerate}

\item Obtener un modelo que represente el comportamiento de cada clúster.

\begin{enumerate}
\item Una opción consiste en agregar la información de las series de tiempo que componen el clúster considerando la media funcinal, considerando las series como trayectorias de un mismo proceso, esta nueva serie resume el comportamiento de todos los miembros del clúster. Hecho esto, se modela la media funcional que representa el clúster mediante un modelo SARIMA. Así, se obtiene un modelo por cada clúster.
\item La segunda opción consiste de identificar a la serie de tiempo más \textit{central} del clúster, es decir, se halla la serie más cercana, en términos de la métrica elegida, a todas las series del clúster. Identificada esta serie, se procede a modelarla mediante un modelo SARIMAX, que incluye variables exógenas, para ello se consideran las series temporales asociadas a datos de clima (precipitación, temperatura máxima y mínima y humedad relativa) de la estación de medición más cercana. Por lo tanto de este paso se obtiene también un modelo por clúster.
\item Ahora se puede comparar este par de modelos y optar por aquel que produzca mejores resultados en, términos generales, considerando criterios como la cantidad de Información, y el poder predictivo.

\end{enumerate}
\item Una vez elegido el modelo para cada clúster, se procede a modelar cada una de las 179 series de caudales. Para ello, se recicla información del modelo del clúster. Por ejemplo, si el modelo de un clúster	es SARIMA $(p_0,d_0,q_0)$ $(P_0,D_0,Q_0)_s_0$, entonces, para modelar una serie perteneciente a dicho clúster, se hace precisamente mediante un modelo SARIMA fijando los mismos parámetros $p_0, d_0, q_0, P_0, D_0, Q_0, s_0$, y posteriormente estimando los coeficientes de los polinomios en retardos asociados a este modelo. 

\end{enumerate}

Es decir, al aplicar esta metodología es necesario analizar una serie de tiempo por cada clúster, en lugar de analizar 179. A continuación se muestran los resultados obtenidos en cada etapa.

\paragraph{Nota.-} Toda esta metodología se automatizó, mediante la creación de una aplicación web, disponible al público, basada completamente en el lenguaje de programación R (versión 3.5). Puede ver a detalle el desarrollo del código para esta investigación en el apéndice \ref{chp:webapp}. Todos los resultados mostrados a partir de este punto se pueden obtener en dicha aplicación.


%% !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

\section{Aplicación del Análisis Clúster}


Pues bien, como ya se mencionó en el capítulo anterior, se tienen varias métricas definidas para series de tiempo, de las que se consideran particularmente dos, ($d_{ACF}$ y $d_{PIC}$) relacionadas directamente al modelamiento en retardos de las series de tiempo, sin embargo como ya se comentó $d_{PIC}$ tiene la desventaja de que es necesario conocer a priori la estructura ARIMA de las series para poder calcularla, por esa razón se eligió la métrica $d_{ACF}$, que únicamente se basa en los coeficientes de autocorrelación estimados, los que son sencillos de calcular. A partir de está métrica, se calcula la matriz de distancias $D$, tabla \ref{tab:d_matriz}.



% \section{Elección de Métrica}
% \label{sec3metrica}
% Se selecciona la métrica (en general se usa una función de disimilitud) asociada la Autocorrelación (relación con sus propios retardos), ya que compara el comportamiento Temporal  de una pareja de series por lo que es útil para una posterior modelamiento (SARIMAX por ejemplo, que considera un modelo dependiente del pasado de la serie). A partir de esta pseudo-métrica se genera una matriz de distancias entre todas las estaciones de medición de caudales.
% 
% \[
% d_{ACF}(x,y) = \sqrt{(\hat \rho_x - \hat\rho_y)'\Omega(\hat{\rho}_x-\hat{\rho}_y)}
% \]
% 
% donde $\hat{\rho}$ es el vector de coeficientes de autocorrelación estimados, mientras que $\Omega$ es una matriz de pesos usualmente $\Omega=I$ y así se obtiene la distancia Euclidea entre los coeficientes de autocorrelación, o $\Omega=[cov(\hat\rho)]^{-1}$ y en este caso se obtiene la distancia de Mahalanobis entre los coeficientes de autocorrelación.


\subsection{Representación de $D$}

A partir de la matriz, y usando la técnica de Escalonamiento Multidimensional (MDS), se obtiene una representación en 2 dimensiones de cada serie de tiempo (asociada a una estación de medición de caudales). Es decir, se obtienen 179 puntos en $\R^2$ cuya matriz de distancias es lo más parecida posible a $D$, se muestra dicha representación en la figura \ref{fig:puntosD}



<<fig.width=5,fig.height=4,fig.cap='MDS - Representación en $R^2$ de $D$'>>=
# library(readxl)
# library(ggplot2)
dimR2 <- read_excel("Resultados/1_tabla_dimensionesR2.xlsx",skip=1)
ggplot(dimR2, aes(D1, D2)) + geom_point(size = 2.2,alpha=I(0.4))+theme_minimal()
@

\label{fig:puntosD}



\subsection{Elección del Algoritmo de Agrupamiento}

A partir de la matriz de distancias $D$, y aplicando el tanto el algoritmo de agrupamiento CLARA como PAM, por ejemplo para formar $K=3$ grupos, se obtienen agrupaciones parecidas, tal como se puede ver en la figura \ref{fig:pam} , \ref{fig:clara}. Las ligeras semejanzas en los grupos formados obedece a que el algoritmo CLARA, usa el algoritmo PAM pero con remuestreo. Sin embargo, la diferencia radica en la velocidad de ejecución de ambos algoritmos, como ya lo se mencionaron en el capítulo anterior, el algoritmo CLARA es mucho más eficiente en la formación de grupos (considerando el tiempo de ejecución).



\begin{figure}[H]
\centering
\includegraphics[scale=0.45]{Resultados/1_Pamk3}
\caption{Clústers generados con PAM}\label{fig:pam}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[scale=0.45]{Resultados/1_Clarak3}
\caption{Clústers generados con CLARA }\label{fig:clara}
\end{figure}




\subsection{Elección de número de clústers}
En esta sección, se hace uso del estadístico GAP, antes descrito, que permitirá hallar el número más adecuado de grupos, que hay que formar. Se resumen los resultados de este estadístico, para distintos número de clústers formados con el algoritmo CLARA, en la figura \ref{fig:k_opt}.

\begin{figure}[H]
\centering
\includegraphics[scale=0.65]{Resultados/4_k_optimo_clusters}
\caption{Número Óptimo de Clusters }\label{fig:k_opt}
\end{figure}

Como se puede observar, el número óptimo de clústers en los que se debe agrupar las series de tiempo es $K=4$.


\subsection{Características de Clústers formados}
Elegido el número de clústers adecuado, se ejecuta el algoritmo CLARA con $K=4$ número de clústers, y se obtienen los distintos grupos a los que corresponde cada serie. A continuación, se analizarán distintas representaciones de los clústers.

\begin{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item \textit{Representación en $\R^2$.} Como se puede apreciar en la figura \ref{fig:puntosR2}, las envolventes convexas de los puntos de cada clúster forman grupos bien definidos de puntos (estaciones), que a pesar de estar bastante cercanos, ninguno de ellos se sobrepone a los otros.

\begin{figure}[H]
\centering
\includegraphics[scale=0.65]{Resultados/2_plot_cluster_dimensiones}
\caption{Representación de Clústers en $\R^2$ }\label{fig:puntosR2}
\end{figure}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item \textit{Representación geográfica.} Como se puede apreciar en la figura \ref{fig:mapa}, se observa que a diferencia de la representación de las estaciones en $\R^2$, no se tienen regiones bien definidas, hay clústers que poseen estaciones (de otros clústers) dentro de la región que delimitan sus elementos, por lo que parecerían mezclarse. Cabe la pena destacar que, viendo con mayor detalle, las serie de un mismo clúster tienden a disponerse sobre la ribera de un mismo río, como se ve por ejemplo en la figura \ref{fig:mapa_zoom}, esto se explicaría por la elección de la métrica con la que se construyeron los clústers, ya que considera la estructura temporal del caudal (medido en las estaciones) y deja de lado la escala. Así si en dos estaciones los caudales crecen (o decrecen) en espacios de tiempo parecidos, y si considerar a que escala, entonces su distancia $d_{ACF}$ será pequeña.


\begin{figure}[H]
\centering
\includegraphics[scale=0.45]{Resultados/3_mapa_clusters}
\caption{Representación Geográfica de Clústers}\label{fig:mapa}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[scale=0.55]{Resultados/3_mapa_zoom}
\caption{Acercamiento a Clúster (representación Geográfica)}\label{fig:mapa_zoom}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item \textit{Gráfico de las Series de Tiempo.} Como se puede observar en la figura \ref{fig:serie_clust1.1}, y como era de esperarse, las series de tiempo del Clúser 1, tiene un comportamiento parecido en todo el periodo considerado, variando solo en escala. Lo propio sucede en el Clúster 2 y 4, como se pude observar en las figuras \ref{fig:serie_clust1.2}, \ref{fig:serie_clust1.4}. Mientras que el Clúster 3 se observan series que parecen tener un comportamiento temporal menos parecido que el visto en los otros clústers, aunque tras una observación más minuciosa se observa que en realidad las series son parecidas considerando unos retardos.
% Resultados/Cluster 1/1_series_cluster.png
\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{Resultados/Cluster1/1_series_cluster}
\caption{Series de Tiempo del Clúster 1}\label{fig:serie_clust1.1}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{Resultados/Cluster2/1_series_cluster}
\caption{Series de Tiempo del Clúster 2}\label{fig:serie_clust1.2}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{Resultados/Cluster3/1_series_cluster}
\caption{Series de Tiempo del Clúster 3}\label{fig:serie_clust1.3}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{Resultados/Cluster4/1_series_cluster}
\caption{Series de Tiempo del Clúster 4}\label{fig:serie_clust1.4}
\end{figure}





\end{enumerate}






%----------------------------------------------------------------------

% 
% \begin{figure}[h]
% \caption{Mapa de Clústers}
% \includegraphics[width=15cm]{Cap3-Metodologia/Capture1.png}
% \label{fig:mapa_clust}
% \centering
% \end{figure}
% 
% 
% \begin{figure}[h]
% \caption{Series del Clúster 1}
% \includegraphics[width=15cm]{Cap3-Metodologia/Capture2.png}
% \label{fig:clust1}
% \centering
% \end{figure}

% \section{Análisis de Componente Principales Funcional}
% 
% El ACP típico se encarga de reducir la dimensión de un conjunto de datos mediante el cálculo de un grupo mucho menor de variables ortogonales que mejor representan el conjunto original de datos.
% Análogamente el análisis de componentes principales funcionales (ACPF) es una extensión del ACP clásico en el que las componentes principales están representadas por funciones y no por vectores, como lo detallamos en el capítulo anterior. 
% 
% Así, podemos usar todas las series de tiempo asociadas a los caudales de un clúster para hallar esta función (o funciones) que representan el comportamiento de todas las series del clúster. Esto bajo el supuesto de que todas las series de un clúster, son en realidad trayectorias de un mismo proceso estocástico. 
% 
% 
% \subsection{ACPF de los Clústers}
% En la figura \ref{fig:acp_summ1} podemos observar, en la esquina superior izquierda, un gráfico que muestra con cuantas observaciones se cuenta en cada punto de tiempo $t$, vemos que se cuenta con más de 4 observaciones, esto debido a que consideramos que cada serie del clúster conforma una observación del proceso. En la parte superior derecha podemos observar la función media del proceso, como vemos esta muestra un comportamiento estacional parecido al de las series que componen el clúster, por lo que más adelante la consideraremos como una candidata a ser representante del clúster, esto a pesar de que en un principio se planeaba usar una de las componentes principales con ese fin. En la parte inferior izquierda encontramos un gráfico que representa el porcentaje de variabilidad explicada por cada componente principal, como se puede observar la primera componente explica el $99\%$ de la variabilidad del proceso. Finalmente, el gráfico restante representa las 3 primeras componentes principales (funcionales), vemos que la primera de ellas es una curva suave casi constante, que no posee un comportamiento estacional, razón por la que se la descarta como posible serie representante del clúster.
% 
% \begin{figure}[H]
% \includegraphics[width=15cm]{1_Cluster/ACPF}
% \caption{ACPF del Series del Clúster 1}
% \label{fig:acp_summ1}
% \centering
% \end{figure}
% 
% Otro gráfico interesante de analizar, es el de la covarianza, recordando que en el caso funcional la función de covarianza es una superficie. La covarianza estimada del proceso asociado al clúster 1 se ve en la parte izquierda de la figura \ref{fig:covar1}, como era de esperarse es una superficie con picos y valles, que indica el comportamiento estacional de todas las series que componen el clúster. 
% 
% \begin{figure}[H]
% \includegraphics[width=15cm]{1_Cluster/covarianza}
% \caption{Superficie de Covarianza Estimada (Clúster 1)}
% \label{fig:covar1}
% \centering
% \end{figure}
% 
% En la parte derecha de la misma figura encontramos un gráfico de modos de variación, este gráfico se usa para identificar niveles inusuales de variación en un proceso que esta compuesto por varias réplicas (trayectorias), cerca de la franja amarilla vemos hallamos trayectorias (series) cuyo comportamiento es más usual, es decir, la mayoría de trayectorias sigue esa tendencia, mientras que hacía los extremos (en color azul oscuro) encontramos las trayectorias menos comunes. Podemos evidenciar de igual manera un comportamiento periódico que es otra evidencia más de la estacionalidad que poseen las series del clúster. 
% 
% \paragraph{Observación.} Las gráficas correspondientes a los otros tres clústers se encuentran en el apéndice \ref{ap:acpf}.
% 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Modelamiento de Series de tiempo}

En esta sección, se plantearán dos modelos para cada clúster. Por una parte, se plantea un modelo SARIMA aplicado a un representate del clúster, una primera idea era considerar la como serie representativa a la primera componente principal obtenida del ACP funcional del clúster, si embargo como se pudo constatar en la sección anterior, dicha serie no recoge el comportamiento estacional de los caudales, por esta razón se optó por elegir a la media funcional de las series (vistas como trayectorias de un mismo proceso estocástico), que como se vio tiene un comportamiento bastante similar, aunque suavizado, al de todas las series del clúster.

El segundo modelo que se plantea es un modelo SARIMAX aplicado a la serie \textit{medoide} del clúster, es decir, aquella serie más centralmente ubicada (en términos de la métrica $d_{ACF}$), estas series se obtienen durante la ejecución del algoritmo de agrupamiento CLARA (y también PAM). Considerando en este caso como variables regresoras a las series climáticas, de la estación geográficamente más cercana a la estación de medición de caudales.

A continuación, se muestra un paso previo, la limpieza de los datos que se poseen, necesaria para un correcto modelamiento de series temporales.

\paragraph{Limpieza de Datos de Clima} Un punto importante previo al modelamiento, es la limpieza de los datos. En este caso se cuenta con una alta presencia de valores perdidos especialmente en las series asociadas a variables Climáticas. Por lo que se decidió retirar todas aquellas series que contengan más del $10\%$ de valores perdidos. 
Mientras que para las restantes, se aplica el algoritmo de limpieza a los valores perdidos de las series climáticas  (\ref{sec:limpieza}). 

Pues bien, aplicando el algoritmo de de limpieza a las 4 variables climáticas (Precipitación, temperatura máxima, temperatura mínima, y humedad relativa), se obtuvieron valores simulados que concuerdan con los valores conocidos, considerando que las series, luego de este proceso de limpieza, no alteraron su estructura general, tal como se puede ver en la figura \ref{fig:climaLimp2}.



\begin{figure}[H]
\centering
\includegraphics[width=10cm]{Cap3-Metodologia/limpieza.png}
\caption{Serie de Tiempo Climática}
\label{fig:clima2}

\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=10cm]{Cap3-Metodologia/limpieza2.png}
\caption{Serie de Tiempo Climática Corregida}
\label{fig:climaLimp2}

\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \section{Agrupar datos de Caudales y Clima}
% 
% Una vez corregidas las series climáticas, el criterio para agrupar las series climáticas con series de caudales de determinado clúster es el siguiente:  Para cada serie de Caudales del clúster se busca la serie climática de la estación más cercana, 
% 
% Finalmete esta lista de estaciones climáticas (y las 4 variables que la conforman) constituyen las variables explicativas del modelo que plantearemos adelante para poder explicar el comportamiento del Caudal de cada Clúster, es decir, de la serie de Caudales que representa el clúster obtenida del ACP-Funcional.
% 
% \begin{figure}[h]
% \caption{Serie de Tiempo Climática Corregida}
% \includegraphics[width=16cm]{Cap3-Metodologia/vazclim.png}
% \label{fig:acpf1}
% \centering
% \end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Modelo SARIMA del Clúster}

Como se mencionó anteriormente, se modelará una serie representante del clúster, en este caso la media funcional de las series de caudales que lo componen (ver figura \ref{fig:sarima_serie}), para ello se sigue la metodología Box y Jenkins, por lo que se analizará en primer lugar la función de Autocorrelación y Autocorrelación Parcial de la serie, como se puede ver en la figura \ref{fig:sarima_acf}, se tienen picos fuera de las bandas de confianza, que se repiten periódicamente (cada 12 retardos). 

<<>>=
vaz_acp = read_excel("Resultados/Cluster1/vaz_acp_clust1.xlsx")
vaz_acp$Fecha = as.Date(vaz_acp$Fecha)
vaz = vaz_acp$VazoePCA
vazd1 = diff(vaz,lag=12,differences = 1)
@


%  Corregir con graficos R



% \begin{figure}[h]
% \centering
% \includegraphics[width=13cm]{1_Cluster/sarima_serie}
% \caption{Media Funcional (Clúster 1)}
% \label{fig:sarima_serie}
% 
% \end{figure}


% \begin{figure}[H]
% \centering
% \includegraphics[width=13cm]{1_Cluster/sarima_autocorr1}
% \caption{Función de Autocorrelación: Media Funcional (Clúster 1)}
% \label{fig:sarima_acf}
% 
% \end{figure}
% 
% \begin{figure}[H]
% \centering
% \includegraphics[width=13cm]{1_Cluster/sarima_autocorrP1}
% \caption{Función de Autocorrelación: Media Funcional (Clúster 1)}
% \label{fig:sarima_pacf}
% 
% \end{figure}



<<eval=FALSE>>=
#============    Funcion de Graficas Series de Tiempo    =======================

ts_ggplot = function(serieDF , n_variable=3 , ylabel ="Caudal"){
  serNomb = names(serieDF)
  serNomb = paste0("`",serNomb,"`")
  ggplot(data = serieDF, 
         aes_string(x = "Fecha", 
                    y = serNomb[n_variable] )) +
    geom_line(size = 0.7) + 
    theme_minimal() +
    scale_x_date(                                        
      breaks = "6 months",
      date_labels = "%b %Y"
    )+
    labs(
      # title = "Caudal del clúster 1", 
      # subtitle = "Media Funcional",
      y = ylabel
    )+
    theme(
      axis.text.x=element_text(size = 6 , angle=90),
      axis.text.y=element_text(size = 6 )
    )
  
  # return(p1)
}

@



<<eval=FALSE>>=
#============    Funcion de Graficas Autocorrelación y Parcial    =======================


acf_ggplot = function(serie){
  
  acf_vz = autoplot(acf(serie,lag.max = 36, plot = FALSE),
                    conf.int.fill = '#0000FF', 
                    conf.int.value = 0.8, 
                    conf.int.type = 'ma') + 
    theme_minimal() +
    labs(
      title = "Autocorrelación"#,
      # subtitle = "Media Funcional",
      # y = "Caudal"
    )
  
  
  pacf_vz = autoplot(pacf(serie,lag.max = 36, plot = FALSE),
                     conf.int.fill = '#0000FF', 
                     conf.int.value = 0.8, 
                     conf.int.type = 'ma') + 
    theme_minimal() +
    labs(
      title = "Autocorrelación Parcial"#,
      # subtitle = "Media Funcional",
      # y = "Caudal"
    )
  
  grid.arrange(
    grobs = list(acf_vz,pacf_vz),
    # widths = c(3, 2),
    layout_matrix = rbind(c(1), c(2))
  )
  
  
}



@



<<fig.pos= "H", fig.height=5, fig.cap="\\label{fig:sarima_serie} Caudal - Clúster 1">>=

ts_ggplot(vaz_acp)

@



<<fig.pos= "H",fig.height=5,fig.cap="\\label{fig:sarima_acf} Función de Autocorrelación Caudal - Clúster 1">>=

acf_ggplot(vaz)

@







Es evidente que esta serie no es estacionaria, y que es necesaria una diferenciación de tipo estacional (ver figura \ref{fig:sarima_seried1}). Después de diferencial estacionalmente, se tiene una función de autocorrelación que no decrece rápidamente y que en varios retardos se encuentra fuera de las bandas de confianza (ver figura \ref{fig:sarima_acf2}). Aunque se puede aplicar el test de Dickey Fuller para ver si es necesaria una diferenciación (no estacional) adicional.
% Test de DICKEY FULLER


<<highlight=FALSE, fig.pos= "H" , fig.cap="Test de Dickey Fuller - Caudal">>=

# vaz_acp = read_excel("Resultados/Cluster1/vaz_acp_clust1.xlsx")
# vaz = vaz_acp$VazoePCA
# vazd1 = diff(vaz,lag=12,differences = 1)
# tseries::adf.test(vaz_acp$VazoePCA)

tseries::adf.test(vazd1)

@
\label{tab:dfuller}





<<fig.pos= "H",fig.height=3, fig.cap="\\label{fig:sarima_seried1} D(Caudal,12) - Clúster 1">>=
dvaz = data.frame(Fecha=vaz_acp$Fecha[-(1:12)],
                  DVazoePCA = vazd1)

ts_ggplot(dvaz, n_variable = 2, ylabel = "D(Caudal,12)")
@



<<fig.pos= "H",fig.height=5,fig.cap="\\label{fig:sarima_acf2} Función de Autocorrelación D(Caudal,12) - Clúster 1">>=

acf_ggplot(dvaz$DVazoePCA)

@



%%%%%%%%%%%  Funcion crear tablas modelos 


<<eval=TRUE, echo=FALSE>>=

tab_model = function(modelo,caption_text=NULL,label_text = NULL,orientacion="vertical"){
  options(digits=4)
  t_model = coeftest(modelo)
  m = dim(t_model)[1]
  tabla = data.frame("Coef"=NA,"Estimate"=NA,"Std.Error"=NA,"z-value"=NA,"Pr(>|z|)"=NA)
  for(i in seq(m)){
    tabla[i,] = c(0,as.numeric(t_model[i,]))
    # tabla[i,1] = 0
    # tabla[i,2] = as.numeric(t_model[i,1])
    # tabla[i,3] = as.numeric(t_model[i,2])
    # tabla[i,4] = as.numeric(t_model[i,3])
    # tabla[i,5] = as.numeric(t_model[i,4])
  }
  names(tabla) = c("Coef","Estimate","Std.Error","z-value","Pr(>|z|)")
  tabla$Coef = rownames(t_model)
  Pval = tabla$`Pr(>|z|)`
  rangos = cut(Pval,breaks = c(0,0.001,0.01,0.05,0.1,1),
               labels = c("***","**","*","."," "))
  rangos[is.na(rangos)] = "   "
  tabla$Signif = rangos
  
  # Caption   --------
  if(is.null(caption_text)){
    caption_text0 = "Modelo"
  }else{
    caption_text0 = paste("Modelo",caption_text)
  }
  
  # Texto CAPTION  ------
  texto = NULL
  if(is.null(label_text)){
    texto = caption_text0 
  }else{
    texto = paste0("\\label{",label_text,"}",caption_text0)
  }
  
  #Estadisticos AIC BIC LOG -----
  nota = paste0("sigma^2 = ", round(modelo$sigma2,2),", ",
                "loglikelihood = ", round(modelo$loglik,2),", ",
                "AIC = ", round(aic(modelo),2),", ",
                "BIC =", round(bic(modelo),2),", ",
                "Hannan-Quinn =", round(hannanQ(modelo),2)
  )
  
  
  # Tabla final ------
  if(orientacion =="horizontal"){
    kable(tabla,format = "latex",
          escape = F,booktabs = T,
          # label = label_text,
          # caption = caption_text0) %>% 
          caption = texto) %>%
      footnote(general = nota,
               general_title = "Resumen:",
               title_format = c("italic"),
               # footnote_as_chunk = T,
               threeparttable = T
      ) %>%
      kable_styling(latex_options = c("striped")) %>%
      landscape()
  }else{
    kable(tabla,format = "latex",
          escape = F,booktabs = T,
          # label = label_text,
          # caption = caption_text0) %>% 
          caption = texto) %>%
      footnote(general = nota,
               general_title = "Resumen:",
               title_format = c("italic"),
               # footnote_as_chunk = T,
               threeparttable = T) %>%
      kable_styling(latex_options = c("striped"))
  }
  
}


@



<<eval=FALSE>>=
tab_model = function(modelo,caption_text=NULL,label_text = NULL){
  options(digits=4)
  t_model = coeftest(modelo)
  #print(t_model)
  m = dim(t_model)[1]
  tabla = data_frame("Coef"=NA,"Estimate"=NA,"Std.Error"=NA,"z-value"=NA,"Pr(>|z|)"=NA)
  for(i in seq(m)){
    #print( c(0,as.numeric(t_model[i,])) )
    #tabla[i,] = c(0,as.numeric(t_model[i,]))
    tabla[i,1] = 0
    tabla[i,2] = t_model[i,1]
    tabla[i,3] = t_model[i,2]
    tabla[i,4] = t_model[i,3]
    tabla[i,5] = t_model[i,4]
  }
  names(tabla) = c("Coef","Estimate","Std.Error","z-value","Pr(>|z|)")
  tabla$Coef = rownames(t_model)
  Pval = tabla$`Pr(>|z|)`
  #print(tabla)
  rangos = cut(Pval,breaks = c(0,0.001,0.01,0.05,0.1,1),
               labels = c("***","**","*","."," "))
  tabla$Signif = rangos
  
  # Caption   --------
  if(is.null(caption_text)){
    caption_text0 = "Modelo"
  }else{
    caption_text0 = paste("Modelo",caption_text)
  }
  
  # Texto CAPTION  ------
  texto = NULL
  if(is.null(label_text)){
    texto = caption_text0 
  }else{
    texto = paste0("\\label{",label_text,"}",caption_text0)
  }
  
  #Estadisticos AIC BIC LOG -----
  nota = paste0("sigma^2 = ", round(modelo$sigma2,2),", ",
                "loglikelihood = ", round(modelo$loglik,2),", ",
                "AIC = ", round(aic(modelo),2),", ",
                "BIC =", round(bic(modelo),2),", ",
                "Hannan-Quinn =", round(hannanQ(modelo),2)
  )
  
  
  # Tabla final ------
  kable(tabla,format = "latex",
        escape = F,booktabs = T,
        caption = texto) %>% 
    footnote(general = nota,
             general_title = "Resumen:",
             title_format = c("italic"),
             # footnote_as_chunk = T,
             threeparttable = T
    )
}

@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%  Tabla resumen Modelo 1



% \newpage
Como se puede ver en \ref{tab:dfuller}, el test de Dickey Fuller arroja un $\text{P-valor} = 0.016 < 0.05$, por lo que se concluye que el proceso ya es estacionario. Pues bien, en este punto se conocen los parámetros $d=0$ y $D=1$ del modelo SARIMA, resta identificar los órdenes $p, P, q$ y $Q$ de los polinomios Autoregresivos y Medias Móviles. Para ello, nótese que la función de autocorrelación parcial posee picos fuera de las  bandas hasta el retardo 5, por lo que la parte autoregresiva del modelo podría incluir 5 retardos, por lo tanto, se empieza planteando un modelo SARIMA$(5,0,0)(0,1,0)_{12}$. 

<<fig.pos="H">>=
{
  p=5;q=0
  P=0;Q=0
  d=0;D=1
  p_lags = rep(NA, p);q_lags = rep(NA, q)
  P_lags = rep(NA, P);Q_lags = rep(NA, Q)
  
  retardos = c(p_lags,q_lags,P_lags,Q_lags)
  if(d==0 & D==0) retardos = c(retardos,NA)
}

ms1 = arima(vaz,order = c(p,d,q),
            seasonal = list(order = c(P,D,Q), period = 12),
            fixed = retardos)

# summary(ms1)
# coeftest(ms1)
tab_model(ms1,label_text = "mod:sarima1",caption_text = "SARIMA$(5,0,0)(0,1,0)_{12}$")
@


Como se puede ver en la tabla \ref{mod:sarima1}, los coeficientes asociados a los dos mayores retardos del polinomio AR son no significativos, por lo que es posible que sea necesario quitarlos del modelo. Por otra parte analizando los residuos del modelo, se puede observar por una parte que la función de Autocorrelación se encuentra dentro de las bandas de confianza, excepto en el retardo 12, por otro lado analizando los P-valores del Test Portmanteau (ver figura \ref{fig:sarima_residJ1}), en la versión de Ljung-Box, se observa que estos son menores a 0.05 a partir del retardo 7, por lo que se concluye que los residuos son significativos. Por lo tanto, no se rechaza la independencia de los residuos de este modelo, así que es necesario modificarlo.



% \label{fig:sarima_resid1}


<<fig.pos= "H",fig.height=7,fig.cap="\\label{fig:sarima_residJ1} Residuos - Test Portmanteau (Ljung-Box) SARIMA(5,0,0)(0,1,0)">>=
tsdiag(ms1,gof.lag = 24)
@

% \label{fig:sarima_residJ1}


Considerando ahora un orden menor del polinomio autoregresivo, debido a que los coeficiente asociados a los mayores retardos resultaron no ser significativos. Tras probar con el modelo SARIMA$(4,0,0)(0,1,0)_{12}$, se puede ver que todos sus coeficientes son significativos (\ref{mod:sarima_resid12}).


<<fig.pos="H" >>=
{
  p=4;q=0
  P=0;Q=0
  d=0;D=1
  p_lags = rep(NA, p);q_lags = rep(NA, q)
  P_lags = rep(NA, P);Q_lags = rep(NA, Q)
  
  retardos = c(p_lags,q_lags,P_lags,Q_lags)
  if(d==0 & D==0) retardos = c(retardos,NA)
}

ms1 = arima(vaz,order = c(p,d,q),
            seasonal = list(order = c(P,D,Q), period = 12),
            fixed = retardos)

# summary(ms1)
# kable(tab_model(ms1),format = "latex",escape = F,booktabs = T)
tab_model(ms1,label_text = "mod:sarima_resid12",caption_text = "SARIMA(4,0,0)(0,1,0)_{12}")
@


En cuanto a los residuos de este modelo se puede ver en la figura \ref{fig:sarima_resid12} que la función de autocorrelación tiene un pico fuera de las bandas únicamente en el retardo 12, por lo que es posible que sea necesario incorporar un retardo del polinomio media móvil (MA) o autoregresivo (AR) estacional. Además, se puede observar que los p-valores del estadístico de Ljung-Box aun son menores que 0.05 después del séptimo retardo.


<<fig.pos= "H",fig.height=7,fig.cap="\\label{fig:sarima_resid12} Residuos - Test Portmanteau (Ljung-Box) SARIMA(4,0,0)(0,1,0)" >>=
# checkresiduals(ms1)
tsdiag(ms1, gof.lag = 24)
# acf_ggplot(ms1$residuals)
@


Pues bien, agregando ahora al modelo el primer retardo del polinomio autoregresivo estacional, con lo que se plantearía un modelo SARIMA$(4,0,0)(1,1,0)_{12}$. Tal como se puede ver en la tabla \ref{mod:sarima_resid13}, se obtiene un modelo con todos los coeficientes significativos, y con residuos independientes, tal como se puede ver en la figura \ref{fig:sarima_resid13}. 

<<fig.pos="H" >>=
{
  p=4;q=0
  P=1;Q=0
  d=0;D=1
  p_lags = rep(NA, p);q_lags = rep(NA, q)
  P_lags = rep(NA, P);Q_lags = rep(NA, Q)
  
  retardos = c(p_lags,q_lags,P_lags,Q_lags)
  if(d==0 & D==0) retardos = c(retardos,NA)
}

ms1 = arima(vaz,order = c(p,d,q),
            seasonal = list(order = c(P,D,Q), period = 12),
            fixed = retardos)

# summary(ms1)
# coeftest(ms1)
# kable(tab_model(ms1),format = "latex",escape = F,booktabs = T)
tab_model(ms1,label_text = "mod:sarima_resid13",caption_text = "SARIMA$(4,0,0)(1,1,0)_{12}$")
@


<<fig.pos= "H",fig.height=7,fig.cap="\\label{fig:sarima_resid13} Residuos - Test Portmanteau (Ljung-Box) SARIMA(4,0,0)(1,1,0)" >>=
# checkresiduals(ms1)
tsdiag(ms1, gof.lag = 24)
# acf_ggplot(ms1$residuals)
@


Tras analizar estos estos tres modelos, y considerando los criterios de información como los dados por los estadísticos AIC, BIC, y Hannan Quinn, se elige como mejor modelo al SARIMA$(4,0,0)(1,1,0)_{12}$, ya que minimiza todos estos criterios, obteniendo $AIC=\Sexpr{aic(ms1)} $, $BIC=\Sexpr{bic(ms1)}$, Hannan Quinn$=\Sexpr{hannanQ(ms1)}$. Además posee residuos que se comportan como ruido blanco, según las pruebas, de  varianza menor. Finalmente se puede representar este modelo mediante la siguiente ecuación:

\begin{equation}\label{eq:sarima}
(1- 2.659 B + 2.610 B^2 - 1.181 B^3  + 0.239 B^4)(1+ 0.738 B^{12})\Delta_{12} Y_t = \varepsilon_t
\end{equation}

\paragraph{Observación.} Los modelos hallados para cada uno de los cuatro clúster, siguiendo el mismo método descrito en esta sección, se encuentra en el apéndice \ref{ap:sarima}. Así mismo puede encontrar los coeficientes estimados, significancia de los mismos, y estadísticos de la bondad de ajuste, de los modelos de cada uno de las series asociadas a las estaciones que componen cada clúster. Se comentará más adelante, los resultados obtenidos en términos generales comparándolos con los modelos obtenidos usando los modelos SARIMAX que se presentan a continuación.






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%     SARIMAX      %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newpage


\subsection{Modelo SARIMAX del Clúster}

En esta sección se buscará un segundo modelo que represente el Caudal para el clúster 1, para ello se considerará la serie \textit{medoide} del clúster, se halla una por cada clúster durante la ejecución del algoritmo CLARA, y se usará como representante del comportamiento del caudal de este clúster. Se aplicará un modelo SARIMAX usando como variables regresoras a la Precipitación, Temperatura Máxima, Temperatura Mínima, y Humedad Relativa medidas en la estación más cercana (geográficamente) a donde se midió el caudal asociado al medoide (ver figuras \ref{fig:mapa_vaz}, \ref{fig:mapa_clm}.


<<>>=
# Seleccionar cluster
cl = 1 # Cluster 
est_vaz = "MACHADINHO (217)"
est_clim = "CAMPOS NOVOS(83887)"
@


En este caso, el medoide correspondiente al clúster 1 es el de la estación \Sexpr{"MACHADINHO (217)"} (ver figura \ref{fig:sarimax_serie}), mientras que la estación de clima más cercana, asociada a esta, es \Sexpr{"CAMPOS NOVOS(83887)"} (ver figura \ref{fig:sarimax_serieCl}). Siguiendo la metodología propuesta por Box y Jenkins, cuya aplicación se encuentra a detalle en \citeauthor{novales1993econometria} \citeyear{novales1993econometria}, se obtiene lo siguiente.


<<>>=
# Carga de Datos  =========================================

{
  # Datos para modelo SARIMAX  
  XData = read_excel(paste0("Resultados/Cluster",cl,"/clima.xlsx"),
                     sheet = "Sheet1", skip = 1)
  XData = XData[,-1]
  
  VazData = read_excel(paste0("Resultados/Cluster",cl,"/caudal.xlsx"), 
                       sheet = "Sheet1", skip = 1)
  VazData = VazData[,-1]
  
  # Funcion de particion Data  
  particion = function(filas=147,parte=0.8,semilla = 1){
    set.seed(semilla)
    X = 1:filas
    n = round(filas*parte)
    ind_train = 1:n
    ind_test = X[-ind_train]
    return(list("train" = ind_train,"test"=ind_test))
  }
  
  # Particionar data
  n = dim(XData)[1]
  fecha0r = c(2000,01)
  
  
  Xtrain = XData#[particion(filas=n)$train,]
  VazTrain = VazData#[particion(filas=n)$train,]
  #Datos Completos  
  BDDclust = VazTrain %>% inner_join(Xtrain,by="Fecha")
  #
  Xtrain = ts(Xtrain[,-1],start=fecha0r,frequency = 12)
  VazTrain = ts(VazTrain[,-1],start=fecha0r,frequency = 12)
  remove(n)
}

@


<<fig.pos="H",fig.height=5, fig.cap="\\label{fig:sarimax_serie} Caudal - Estación Machadinho">>=
VazData2 = VazData
VazData2$Fecha = as.Date(VazData2$Fecha)
ts_ggplot(VazData2,n_variable = 2)
@




<<fig.pos="H",fig.height=8,fig.cap="\\label{fig:sarimax_serieCl} Series Climáticas - Estación Campos Novos">>=

XData2 = XData
XData2$Fecha = as.Date(XData2$Fecha)

p1 = ts_ggplot(XData2,n_variable = 2,ylabel = "Precipitación") + 
  theme(axis.title.y = element_text(size = 8))
p2 = ts_ggplot(XData2,n_variable = 3,ylabel = "Temperatura Maxima") + 
  theme(axis.title.y = element_text(size = 8))
p3 = ts_ggplot(XData2,n_variable = 4,ylabel = "Temperatura Minima") + 
  theme(axis.title.y = element_text(size = 8))
p4 = ts_ggplot(XData2,n_variable = 5,ylabel = "Humedad Relativa") + 
  theme(axis.title.y = element_text(size = 8))

grid.arrange(
  grobs = list(p1,p2,p3,p4),
  # widths = c(3, 2),
  layout_matrix = rbind(c(1), c(2), c(3), c(4))
)
@


\subsubsection{Preblanqueo de Series}

En primer lugar se necesita \textit{preblanquear} las series, tanto la serie de caudal, como las cuatro series asociadas a clima. Para ello se puede analizar sus funciones de autocorrelación y realizar el test de Dickey Fuller, a fin de identificar si es necesario diferenciar las series. 


\begin{itemize}
\item Para preblanquear la serie de caudales del la estación \Sexpr{est_vaz} se analiza la función de autocorrelación  (ver figura \ref{fig:blan_acf_vz1}), que si bien es cierto presenta picos de periodicidad 12, estos no se encuentran fuera de las bandas de confianza, es decir, existe la posibilidad de que el proceso sea estacionario, para corroborarlo se puede ejecutar el test de Dickey Fuller (ver \ref{tab:dyf_vz1}), donde se obtiene un P-valor$=0.01$, es decir, se rechaza la existencia de raíces unitarias a favor de la hipótesis alternativa de que la serie es estacionaria, por lo tanto no es necesario diferenciar esta serie.




<<fig.pos="H",fig.height=5,fig.cap='\\label{fig:blan_acf_vz1} Autocorrelación - Caudal'>>=
# acf(as.numeric(VazTrain),lag.max = 36,type = "correlation")
acf_ggplot(as.numeric(VazTrain))

@
% \label{fig:blan_acf_vz1}


<<>>=
tseries::adf.test(VazTrain)
@
\label{tab:dyf_vz1}




\item De igual manera para el caso de la serie asociada a Precipitación, se observa una función de autocorrelación dentro de las bandas de confianza (ver figura \ref{fig:blan_acf_cl1}), con picos fuera de las bandas en los retardos 15 y 30, por lo que da cierto indicio de que esta serie es estacionaria, lo que puede corroborar aplicando el test de Dickey Fuller (\ref{tab:blan_dyf_cl1}), en el que se obtiene un P-valor$=0.01$, es decir, la serie asociada a Precipitación es también estacionaria.



<<fig.pos="H",fig.height=5,fig.cap='\\label{fig:blan_acf_cl1} Autocorrelación Precipitación'>>=
# acf(as.numeric(Xtrain[,1]),lag.max = 36,type = "correlation")
acf_ggplot(as.numeric(Xtrain[,1]))
@


<<>>=
tseries::adf.test(Xtrain[,1])
@
\label{tab:blan_dyf_cl1}


\item Para el caso de la serie asociada a Temperatura Máxima y Mínima, se observa un comportamiento similar de sus funciones de autocorrelación (ver figura \ref{fig:blan_acf_cl2}, \ref{fig:blan_acf_cl3}), ambas con picos periódicos fuera de las bandas de confianza, lo que podría indicar la necesidad de diferenciar estas series estacionalmente.

<<fig.pos="H",fig.height=4,fig.cap='\\label{fig:blan_acf_cl2} Autocorrelación Temperatura Máxima'>>=
# acf(as.numeric(Xtrain[,2]),lag.max = 36,type = "correlation")
acf_ggplot(as.numeric(Xtrain[,2]))
@


<<fig.pos="H",fig.height=4,fig.cap='\\label{fig:blan_acf_cl3} Autocorrelación Temperatura Mínima'>>=
# acf(as.numeric(Xtrain[,3]),lag.max = 36,type = "correlation")
acf_ggplot(as.numeric(Xtrain[,3]))

@


\item Finalmente, analizando la serie asociada a Humedad Relativa (ver figura \ref{fig:blan_acf_cl4}), se observa que la función de autocorrelación presenta picos relativamente pequeños periódicos cada 12 retardos, que apenas salen de las bandas, por lo que es posible que la serie sea estacionaria, para corroborarlo se realiza el test de Dickey Fuller, donde se obtiene un P-valor$=0.01$, es decir, se concluye que la serie es estacionaria, y por lo tanto no es necesario diferenciar esta serie.

<<>>=
tseries::adf.test(Xtrain[,4])
@


<<fig.pos="H",fig.height=5,fig.cap='\\label{fig:blan_acf_cl4} Autocorrelación Humedad Relativa'>>=
# acf(as.numeric(Xtrain[,3]),lag.max = 36,type = "correlation")
acf_ggplot(as.numeric(Xtrain[,4]))

@



\end{itemize}

Como se puede observar en la figura \ref{fig:blanqueadas}, se ha obtenido series estacionarias mediante el proceso de preblanqueo de las series tanto de caudales como climáticas. Por lo que se puede pasar al siguiente paso de la metodología Box y Jenkins para el modelo SARIMAX.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%% Series Preblanqueadas %%%%%%%%%%%%%%%%%%

<<fig.pos="H",fig.height=8, fig.cap='\\label{fig:blanqueadas} Series Blanqueadas'>>=
Vzdiff = window(VazTrain,start = c(2001,1))

Xdiff = diff(Xtrain,lag = 12, differences = 1)
# Precipitacion no necesita diferencias  !!
# Xdiff1= diff(Xtrain[,1],lag = 12, differences = 1)
Xblanc = Xdiff
Xblanc[,1] = window(Xtrain[,1],start = c(2001,1))
####
XblancDF = as.data.frame(Xblanc)

XblancDF$Fecha = XData2$Fecha[-(1:12)]

p1 = ts_ggplot(XblancDF,n_variable = 1,ylabel = "Precipitación") + 
  theme(axis.title.y = element_text(size = 8))
p2 = ts_ggplot(XblancDF,n_variable = 2,ylabel = "Temperatura Maxima") + 
  theme(axis.title.y = element_text(size = 8))
p3 = ts_ggplot(XblancDF,n_variable = 3,ylabel = "Temperatura Minima") + 
  theme(axis.title.y = element_text(size = 8))
p4 = ts_ggplot(XblancDF,n_variable = 4,ylabel = "Humedad Relativa") + 
  theme(axis.title.y = element_text(size = 8))

grid.arrange(
  grobs = list(p1,p2,p3,p4),
  # widths = c(3, 2),
  layout_matrix = rbind(c(1), c(2), c(3), c(4))
)



@




<<datos_transfer>>=
y = Vzdiff
x1 = Xblanc[,1]
x2 = Xblanc[,2]
x3 = Xblanc[,3]
x4 = Xblanc[,4]

@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%    Funciones de Correlacion Cruzada   %%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


<<>>=
ccfab_ggplot = function(serie_y,serie_x = NULL, modelo = NULL,txt_titulo=NULL){
  
  
  ## Correlacion cruzada  GGPLOT  ---
  if(is.null(serie_x)){
    
    if(!is.null(modelo)){
      modx = modelo
      alf = modx$residuals
      s_alf = sd(alf)
      # beta
      bet = forecast::forecast(object = serie_y ,model=modx)
      bet = bet$residuals
      s_bet = sd(bet)
    }else{
      print("Error: Debe ingresar la serie_x o modelo")
    }
    
    cc_ab = autoplot(ccf(as.numeric(alf), as.numeric(bet),
                         lag.max = 36, plot = FALSE),
                     conf.int.fill = '#0000FF', 
                     conf.int.value = 0.8, 
                     conf.int.type = 'ma') + 
      theme_minimal() +
      labs(
        title =TeX("Correlación Cruzada $\\alpha_t$ vs. $\\beta_t$") #,
        # subtitle = "Media Funcional",
        # y = "Caudal"
      )
  }else{
    
    if(is.null(txt_titulo)){
      titulo = "Correlación Cruzada"
    }else{
      titulo = paste("Correlación Cruzada",txt_titulo)
    }
    
    cc_ab = autoplot(ccf(as.numeric(serie_y), as.numeric(serie_x),
                         lag.max = 36, plot = FALSE),
                     conf.int.fill = '#0000FF', 
                     conf.int.value = 0.8, 
                     conf.int.type = 'ma') + 
      theme_minimal() +
      labs(
        title =TeX(titulo) #,
        # subtitle = "Media Funcional",
        # y = "Caudal"
      )
  }
  
  
  return(cc_ab)
  
}
@



<<fig.pos="H",fig.height=8, fig.cap='\\label{fig:cc_exogenas} Corrleaciones Cruzadas - Variables Exógenas'>>=
cp1 =ccfab_ggplot(serie_x = x1,serie_y = x2,txt_titulo = "$x_1$ vs. $x_2$")
cp2 =ccfab_ggplot(serie_x = x1,serie_y = x3,txt_titulo = "$x_1$ vs. $x_3$")
cp3 =ccfab_ggplot(serie_x = x1,serie_y = x4,txt_titulo = "$x_1$ vs. $x_4$")
cp4 =ccfab_ggplot(serie_x = x2,serie_y = x3,txt_titulo = "$x_2$ vs. $x_3$")
cp5 =ccfab_ggplot(serie_x = x2,serie_y = x4,txt_titulo = "$x_2$ vs. $x_4$")
cp6 =ccfab_ggplot(serie_x = x3,serie_y = x4,txt_titulo = "$x_3$ vs. $x_4$")
grid.arrange(
  grobs = list(cp1,cp2,cp3,cp4,cp5,cp6),
  nrow=3,ncol=2#,
  # widths = c(1, 1),
  # layout_matrix = rbind(c(1,2),c(3,4),c(5,6))
  # top = textGrob("Correlaciones Cruzadas",gp=gpar(fontsize=20,font=3))
)

@


<<fig.pos="H",fig.height=8, fig.cap='\\label{fig:cc_output} Corrleaciones Cruzadas - Caudal vs. Variables Exógenas'>>=
cpy1 = ccfab_ggplot(serie_x = x1,serie_y = y,txt_titulo = "$x_1$ vs. $y$")
cpy2 = ccfab_ggplot(serie_x = x2,serie_y = y,txt_titulo = "$x_2$ vs. $y$")
cpy3 = ccfab_ggplot(serie_x = x3,serie_y = y,txt_titulo = "$x_3$ vs. $y$")
cpy4 = ccfab_ggplot(serie_x = x4,serie_y = y,txt_titulo = "$x_4$ vs. $y$")

grid.arrange(
  grobs = list(cpy1,cpy2,cpy3,cpy4),
  nrow=4,ncol=1#,
  # widths = c(1, 1),
  # layout_matrix = rbind(c(1,2),c(3,4),c(5,6))
  # top = textGrob("Correlaciones Cruzadas",gp=gpar(fontsize=20,font=3))
)
@




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\subsubsection{Identificación de Funciones de Respuesta al Impulso}

Siguiendo la metodología de identificación de este modelo, se pasa a la etapa de identificación de las funciones de respuesta al impulso asociadas a las variables climáticas. Considerando lo siguiente:

\begin{itemize}
\item $v^{(1)}(B)$ : Función de respuesta al impulso asociada a la Precipitación $x^{(1)}_t$.
\item $v^{(2)}(B)$ : Función de respuesta al impulso asociada a la Temperatura Máxima $x^{(2)}_t$.
\item $v^{(3)}(B)$ : Función de respuesta al impulso asociada a la Temperatura Mínima $x^{(3)}_t$.
\item $v^{(4)}(B)$ : Función de respuesta al impulso asociada a la Humedad Relativa $x^{(4)}_t$.
\end{itemize}


Como se mostró en el capítulo anterior, esta etapa consiste de hallar modelos SARMA para cada variable exógena, es decir al final de esta etapa se obtienen modelos del tipo:


$$\frac{ \phi_x^{(k)}(B) \Phi_x^{(k)}(B) }{\theta_x^{(k)}(B) \Theta_x^{(k)}(B)} x^{(k)}_t= \alpha^{(k)}_t $$

donde $\alpha^{(k)}_t$ es un r.b. de varianza $\sigma^2_k$, para $k=1,2,3,4$.

A continuación se muestran los 4 modelos SARMA obtenidos, sus coeficientes, significancia, bondad de ajuste y validación de residuos.

\begin{enumerate}

\item Siguiendo la metodología Box y Jenkins clásica, se obtuvo, para la variable Precipitación, un modelo SARMA con parámetros $p=1$ , $P=2$, $q=0$ y $Q=1$. Se muestran los coeficientes de este modelo y su significancia en la tabla \ref{tab:sarma_precip}, se muestra además, en la figura \ref{fig:sarma_precip}, el análisis de los residuos, donde de acuerdo a los P-valores del estadístico de Ljung-Box (Portmanteau), se concluye sigue que los residuos del modelo se comportan como un r.b.

<<model_x1, fig.pos="H">>=
# Modelo X1: PrecipitacaoTotal ------------
{
  p=1;q=0
  P=2;Q=1
  d=0;D=0
  p_lags = rep(NA, p);q_lags = rep(NA, q)
  P_lags = rep(NA, P);Q_lags = rep(NA, Q)
  
  retardos = c(p_lags,q_lags,P_lags,Q_lags)
  if(d==0 & D==0) retardos = c(retardos,NA)
}

# mx1 = arima(Xblanc[,1],order = c(p,d,q),
#             seasonal = list(order = c(P,D,Q), period = 12),
#             fixed = retardos)




# Con Auto ARIMA:
mx1 = auto.arima(Xblanc[,1], max.p = 6, max.q = 6, 
                 max.P = 3, max.Q = 3, max.order = 6,
                 max.d = 2, max.D = 2)

# coeftest(mx1)
# tsdiag(mx1, gof.lag = 24)
tab_model(mx1,label_text = "tab:sarma_precip",caption_text = "SARMA(1,0)(2,1) - Precipitación")

@



<<fig.pos= "H",fig.height=7,fig.cap="\\label{fig:sarma_precip} Residuos SARMA(1,0)(2,1) - Precipitación" >>=

tsdiag(mx1, gof.lag = 24)

@






\item De igual manera, para la variable Temperatura Máxima se obtuvo un modelo SARMA con parámetros $p=4$ , $P=0$, $q=0$ y $Q=2$. Se muestran los coeficientes de este modelo y su significancia en la tabla \ref{tab:sarma_tmax}, se muestra además, en la figura \ref{fig:sarma_tmax}, el análisis de los residuos, donde de acuerdo a los P-valores del estadístico de Ljung-Box (Portmanteau), se concluye sigue que los residuos del modelo se comportan como un r.b.

<< model_x2, fig.pos="H" >>=
# Modelo X2:Temp Max ------------
{
  media = FALSE
  p=4;q=0
  P=0;Q=2
  d=0;D=0
  p_lags = rep(NA, p);q_lags = rep(NA, q)
  P_lags = rep(NA, P);Q_lags = rep(NA, Q)
  
  p_lags[c(2,3)] = 0
  
  retardos = c(p_lags,q_lags,P_lags,Q_lags)
  if(d==0 & D==0 & media) retardos = c(retardos,NA)  # Si include.mean = TRUE  compilar
}

mx2 = arima(Xblanc[,2],order = c(p,d,q),include.mean = media,
            seasonal = list(order = c(P,D,Q), period = 12),
            fixed = retardos)
# coeftest(mx2)

# Con Auto ARIMA:
# mx2 = auto.arima(Xblanc[,2], max.p = 6, max.q = 6, 
#                  max.P = 3, max.Q = 3, max.order = 6,
#                  max.d = 0, max.D = 2)

# coeftest(mx2)
# tsdiag(mx2, gof.lag = 24)
tab_model(mx2,label_text = "tab:sarma_tmax",caption_text = "SARMA(4,0)(0,2) - Temperatura Máxima")

@






<<fig.pos= "H",fig.height=7,fig.cap="\\label{fig:sarma_tmax} Residuos SARMA(4,0)(0,2) - Temperatura Máxima" >>=

tsdiag(mx2, gof.lag = 24)

@







\item Para la variable Temperatura Mínima se obtuvo un modelo SARMA con parámetros $p=2$ , $P=2$, $q=2$ y $Q=1$. Se muestran los coeficientes de este modelo y su significancia en la tabla \ref{tab:sarma_tmin}, se muestra además, en la figura \ref{fig:sarma_tmin}, el análisis de los residuos, donde de acuerdo a los P-valores del estadístico de Ljung-Box (Portmanteau), se concluye sigue que los residuos del modelo se comportan como un r.b.

<<model_x3, fig.pos="H">>=
# Modelo X3: Temp Minina ------------
{
  media = FALSE
  p=2;q=2
  P=2;Q=1
  d=0;D=0
  p_lags = rep(NA, p);q_lags = rep(NA, q)
  P_lags = rep(NA, P);Q_lags = rep(NA, Q)
  
  P_lags[c(1)] = 0
  
  retardos = c(p_lags,q_lags,P_lags,Q_lags)
  if(d==0 & D==0 & media) retardos = c(retardos,NA)  # Si include.mean = TRUE  compilar
}

mx3 = arima(Xblanc[,3],order = c(p,d,q),include.mean = media,
            seasonal = list(order = c(P,D,Q), period = 12),
            fixed = retardos)



# Con Auto ARIMA:
# mx3 = auto.arima(Xblanc[,3], max.p = 6, max.q = 6,
#                  max.P = 3, max.Q = 3, max.order = 6,
#                  max.d = 2, max.D = 2)

# coeftest(mx3)

tab_model(mx3,label_text = "tab:sarma_tmin",caption_text = "SARMA(2,2)(2,1) - Temperatura Mínima")

@


<<fig.pos= "H",fig.height=7,fig.cap="\\label{fig:sarma_tmin} Residuos SARMA(2,2)(2,1) - Temperatura Mínima" >>=

tsdiag(mx3, gof.lag = 24)

@






\item Finalmente para la variable Humedad Relativa se obtuvo un modelo SARMA con parámetros $p=2$ , $P=3$, $q=0$ y $Q=0$. Se muestran los coeficientes de este modelo y su significancia en la tabla \ref{tab:sarma_humed}, se muestra además, en la figura \ref{fig:sarma_humed}, el análisis de los residuos, donde de acuerdo a los P-valores del estadístico de Ljung-Box (Portmanteau), se concluye sigue que los residuos del modelo se comportan como un r.b.

<<model_x4, fig.pos="H">>=
# Modelo X4: Humedad Relativa ------------
{
  p=2;q=0
  P=3;Q=0
  d=0;D=0
  p_lags = rep(NA, p);q_lags = rep(NA, q)
  P_lags = rep(NA, P);Q_lags = rep(NA, Q)
  
  retardos = c(p_lags,q_lags,P_lags,Q_lags)
  if(d==0 & D==0) retardos = c(retardos,NA)
}

# mx1 = arima(Xblanc[,1],order = c(p,d,q),
#             seasonal = list(order = c(P,D,Q), period = 12),
#             fixed = retardos)




# Con Auto ARIMA:
mx4 = auto.arima(Xblanc[,4], max.p = 6, max.q = 6, 
                 max.P = 3, max.Q = 3, max.order = 6,
                 max.d = 2, max.D = 2)

# coeftest(mx3)

tab_model(mx4,label_text = "tab:sarma_humed",caption_text = "SARMA(2,0)(3,0) - Humedad Relativa")

@


<<fig.pos= "H",fig.height=6,fig.cap="\\label{fig:sarma_humed} Residuos SARMA(2,0)(3,0) - Humedad Relativa" >>=

tsdiag(mx4, gof.lag = 24)

@


\end{enumerate}








%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

<<>>=

#============    Funcion de Graficas Correlacion Cruzada    =======================


ccfab_ggplot = function(serie_y,serie_x = NULL, modelo = NULL,txt_titulo=NULL){
  
  
  ## Correlacion cruzada  GGPLOT  ---
  if(is.null(serie_x)){
    
    if(!is.null(modelo)){
      modx = modelo
      alf = modx$residuals
      s_alf = sd(alf)
      # beta
      bet = forecast::forecast(object = serie_y ,model=modx)
      bet = bet$residuals
      s_bet = sd(bet)
    }else{
      print("Error: Debe ingresar la serie_x o modelo")
    }
    
    cc_ab = autoplot(ccf(as.numeric(alf), as.numeric(bet),
                         lag.max = 36, plot = FALSE),
                     conf.int.fill = '#0000FF', 
                     conf.int.value = 0.8, 
                     conf.int.type = 'ma') + 
      theme_minimal() +
      labs(
        title =TeX("Correlación Cruzada $\\alpha_t$ vs. $\\beta_t$") #,
        # subtitle = "Media Funcional",
        # y = "Caudal"
      )
  }else{
    
    if(is.null(txt_titulo)){
      titulo = "Correlación Cruzada"
    }else{
      titulo = paste("Correlación Cruzada",txt_titulo)
    }
    
    cc_ab = autoplot(ccf(as.numeric(serie_y), as.numeric(serie_x),
                         lag.max = 36, plot = FALSE),
                     conf.int.fill = '#0000FF', 
                     conf.int.value = 0.8, 
                     conf.int.type = 'ma') + 
      theme_minimal() +
      labs(
        title =TeX(titulo) #,
        # subtitle = "Media Funcional",
        # y = "Caudal"
      )
  }
  
  
  return(cc_ab)
  
}

# Funcion de respuesta al Impulso  ---
vj_ggplot = function(serie_y,modelo){
  
  modx = modelo
  alf = modx$residuals
  s_alf = sd(alf)
  # beta
  bet = forecast::forecast(object = y,model=modx)
  bet = bet$residuals
  s_bet = sd(bet)
  #correl
  ccx = ccf(as.numeric(alf), as.numeric(bet),lag.max = 36, plot = FALSE)
  v_est = as.numeric(ccx$acf)*(s_alf/s_bet)
  # s_v = sd(v_est)
  
  #intervalos de confianza para la correlacion
  rii = as.numeric(acf(as.numeric(alf),lag.max = 36,plot = F)$acf)
  rjj = as.numeric(acf(as.numeric(bet),lag.max = 36,plot = F)$acf)
  N = modx$nobs
  IntConf_v=c()
  for(k in 1:36){
    aux = 1.96*sqrt((1+2*sum(rii[seq(k)]*rjj[seq(k)]))/(N-k)  ) #Intervalo Correlación
    IntConf_v[k] = aux*(s_alf/s_bet)
  }
  # IntConf = data.frame("k" = seq(36),"IntervaloConf" = IntConf_v)
  # Grafico Vj
  CCdf = data.frame("lags" = as.numeric(ccx$lag),
                    "Vj" = v_est,
                    "IntervaloConf" = c(IntConf_v[seq(36,1)],IntConf_v[1],IntConf_v))
  
  ggplot(data = CCdf,aes(x = lags, xend = lags, y = 0, yend = Vj))+
    geom_segment()+
    geom_line(aes(x=lags, y=IntervaloConf),color="red",linetype="dashed")+
    geom_line(aes(x=lags, y=-IntervaloConf),color="red",linetype="dashed")+
    # geom_hline(yintercept=c(IntConf_v,-IntConf_v), 
    #            linetype="dashed", 
    #            color = "red")+ 
    theme_minimal() +
    labs(
      title =TeX("Coeficientes estimados de $v^{(k)}(B)$") ,
      # subtitle = "Media Funcional",
      y = TeX("v_j^{(k)}"),
      x = TeX("Retardo $j$")
    )
  
}





@



Ahora se puede pasar al paso 3 de la metodología \ref{sec:metod_sarimax}, que consiste de identificar los órdenes de los polinomios $\delta^{(k)}(B)$, $\omega^{(k)}(B)$ que componen las funciones de respuesta al impulso $v^{(k)}(B)$ asociadas a $x_t^{(k)}$. Para ello un primer paso consiste de estimar los coeficientes $v_j^{(k)}$ de las funciones de respuesta al impulso, esto a partir de los valores de la función de correlación cruzada entre $\alpha_t^{(k)}$, hallada  en el paso anterior, y $\beta^{(k)}$ que resulta de aplicar el modelo SARMA de la $k$-ésima variable, pero a la serie $y_t$, es decir:

$$\beta^{(k)} = \frac{ \phi_x^{(k)}(B) \Phi_x^{(k)}(B) }{\theta_x^{(k)}(B) \Theta_x^{(k)}(B)} y_t$$


Los coeficientes estimados de $v_j^{(k)}$ vienen dados por:

$$\hat v_j^{(k)} = \hat\rho_{\alpha\beta}(j) \frac{\hat\sigma_{\beta^{(k)}}}{\hat\sigma_\alpha} $$

Se muestran a continuación, los coeficientes estimados de $v_j^{(k)}$ para cada una de las 4 variables climáticas


\begin{enumerate}


\item Para la variable Precipitación $x_t^{(1)}$, se obtienen los valores estimados de $v_j^{(1)}$ para $j=-36,\dots , 0, \dots, 36$, se representan en la figura \ref{fig:vj1}. Se puede observar en la figura \ref{fig:vj1} que los coeficientes estimados siguen un comportamiento sinusoidal, conducta usual de sucesiones que son solución de ecuaciones en diferencias de segundo grado, por lo tanto se considera $m=2$, retardos del polinomio $\delta^{(1)}(B)$. Como los primeros valores de $v_j^{(1)}$ no son próximos a cero, se toma $b=0$. Cabe recalcar que la función de correlación cruzada tiene un pico en $j=-8$, es decir, la máxima correlación se da entre $y_t$ y $x_{t+8}^{(1)}$, por lo que podría ser necesario considerar $n=8$ retardos del polinomio $\omega^{(1)}(B)$.



<<fig.pos="H", fig.height=7 , fig.cap="\\label{fig:vj1} Coeficientes $v_j$ estimados - Precipitación" >>=
modx = mx1
# x_aux = x1
p1 = ccfab_ggplot(serie_y =  y, modelo = modx)
p2 = vj_ggplot(serie_y =  y, modelo = modx)

grid.arrange(
  grobs = list(p1,p2),
  # widths = c(3, 2),
  layout_matrix = rbind(c(1), c(2))
)
@



\item Para la variable Temperatura Máxima $x_t^{(2)}$, se observa que los coeficientes $\hat v_j^{(2)}$ se encuentran dentro de las bandas de confianza, y no siguen un patron en específico (figura \ref{fig:vj2}). Así, consideramos $m=0$, mientras que como todos los coeficientes $\hat v_j^{(2)}$ se encuentran dentro de las bandas de confianza, entonces se toman $b=0$, y $n=0$. Es decir, se ingresa esta variable sin retardos, como si se tratara de una regresión múltiple.




<<fig.pos="H", fig.height=7, fig.cap="\\label{fig:vj2} Coeficientes $v_j$ estimados - Temperatura Máxima" >>=
modx = mx2
# x_aux = x1
p1 = ccfab_ggplot(serie_y =  y, modelo = modx)
p2 = vj_ggplot(serie_y =  y, modelo = modx)

grid.arrange(
  grobs = list(p1,p2),
  # widths = c(3, 2),
  layout_matrix = rbind(c(1), c(2))
)
@


\item Para la variable Temperatura Mínima $x_t^{(3)}$, se observa que los coeficientes $\hat v_j^{(3)}$, de manera similar a la Temperatura Mínima, se encuentran dentro de las bandas de confianza a excepción de los retardos $j=4$ y $j=-20$, aunque es descartado por el principio de parsimonia (ya que hace que el modelo tenga demasiados coeficientes a estimar y se vuelva más complejo), por lo que se toma $n=4$. Además no siguien un patrón claro (figura \ref{fig:vj3}), por lo tanto se toman $m=0$, $b=0$. 


<<fig.pos="H", fig.height=7, fig.cap="\\label{fig:vj3} Coeficientes $v_j$ estimados - Temperatura Mínima ">>=
modx = mx3
# x_aux = x1
p1 = ccfab_ggplot(serie_y =  y, modelo = modx)
p2 = vj_ggplot(serie_y =  y, modelo = modx)

grid.arrange(
  grobs = list(p1,p2),
  # widths = c(3, 2),
  layout_matrix = rbind(c(1), c(2))
)
@



\item Para la variable Humedad Relativa $x_t^{(4)}$, se observa que los coeficientes $\hat v_j^{(4)}$ se encuentran dentro de las bandas de confianza y no siguen un patrón en particular se toman $b=0$ y $m=0$ , a excepción de los retardos $j=3$ y $j=-7$ (figura \ref{fig:vj4}). Así, posibles valores a considerar son $n=3$ y $n=7$, pero por el principio de parsimonia, solo se considera $n=3$.



<<fig.pos="H", fig.height=7, fig.cap="\\label{fig:vj4} Coeficientes $v_j$ estimados - Humedad Relativa ">>=
modx = mx4
# x_aux = x1
p1 = ccfab_ggplot(serie_y =  y, modelo = modx)
p2 = vj_ggplot(serie_y =  y, modelo = modx)

grid.arrange(
  grobs = list(p1,p2),
  # widths = c(3, 2),
  layout_matrix = rbind(c(1), c(2))
)
@



\end{enumerate}


Identificadas las funciones de respuesta al impulso, para cada una de las variables, considerando únicamente las variables que no se encuentren correlacionadas, 
%estimamos los coeficientes asociados, se muestran los coeficientes en la tabla $$ .
se continua con el paso 4 de la metodología, en este punto se debe identificar la estructura SARMA que compone el modelo SARIMAX, para ello, se consideran dos factores, el primero es que las funciones de respuesta al impulso $v^{(k)}(B)$ tienen como término común al polinomio estacional autoregresivo  (SAR) de grado 2, por lo que se incluye este en el modelo final. Otro factor a analizar es la perturbación $n_t$, para identificar si es necesario incluir más coeficientes tanto en la parte autoregresiva como media móvil del modelo final.

Para ello se procede a modelar $n_t$ precisamente mediante un modelo SARMA. Para este caso, la perturbación viene dada por:

$$n_t^{*} = y_t -  \alpha_t^{(1)}-\alpha_t^{(2)}-\alpha_t^{(3)}-\alpha_t^{(4)}$$

Observando la figura \ref{fig:acf_pertur} se ve que la función de autocorrelación y autocorrleación parcial de $n^{*}_t$ tienen picos fuera de las bandas de confianza en los retardos 1 y 10, en el resto de retardos muestra un comportamiento con picos periódicos, pero dentro de las bandas de confianza, por lo que podría ser necesario incluir polinomios estacionales en el modelo final. 

<<fig.pos="H",fig.height=5 ,fig.cap="\\label{fig:acf_pertur} Autocorrelación $n_t$ ">>=

nt= y - mx1$residuals - mx2$residuals -mx3$residuals - mx4$residuals
acf_ggplot(as.numeric(nt))

@


Tras analizar la función de autocorrelación de $n_t^{*}$, se propone el modelo ARMA$(1,0)$. Como se muestra en la tabla \ref{tab:arma_nt}, todos los coeficientes son significativos, mientras que analizando los residuos del modelo (ver figura \ref{fig:nt_resid}), se observa que todos los P-valores del estadístico Ljung-Box son mayores que 0.05, por lo tanto los residuos se comportan como un ruido blanco.


<<fig.pos="H">>=
mdn = arima(nt,order = c(1,0,0))
tab_model(mdn,label_text = "tab:arma_nt",caption_text = "ARMA(1,0) - Perturbación")

@


<<fig.pos= "H",fig.height=7,fig.cap="\\label{fig:nt_resid} Residuos - Test Portmanteau (Ljung-Box) ARMA(1,0)">>=
tsdiag(mdn,gof.lag = 24)
@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsubsection{Estimación del modelo}

<<>>=
p=1;q=0
P=2;Q=0
d=0;D=1
@


A partir de las anteriores etapas, se identifica un modelo inicial del tipo SARIMAX $(\Sexpr{p},\Sexpr{d},\Sexpr{q})(\Sexpr{P},\Sexpr{D},\Sexpr{Q})_{12}$ con 4 variables exógenas, y con funciones de respuesta al impulso con órdenes $(b_k,m_k,n_k)$ como se muestran a continuación:

<<>>=
# Cambio Nombres Variables Regresoras -----
XblancNmb = Xblanc
colnames(XblancNmb) = c("Precipitacion","TemperaturaMax","TemperaturaMin","HumedadRelativa")

@



<<>>=
{
  media = FALSE
  p=1;q=0
  P=2;Q=0
  d=0;D=1
  p_lags = rep(NA, p);q_lags = rep(NA, q)
  P_lags = rep(NA, P);Q_lags = rep(NA, Q)
  
  #----------------------------------------
  # Ordenes Funciones de Respuesta al Impulso
  tar1 = 8 #Transf - AR  ---- n
  tma1 = 2 #Transf - MA  ---- m
  
  tar2 = 0 #Transf - AR
  tma2 = 0 #Transf - MA
  
  tar3 = 4 #Transf - AR
  tma3 = 0  #Transf - MA
  
  tar4 = 3 #Transf - AR
  tma4 = 0  #Transf - MA
  
  tar1_lags = rep(NA, tar1); tma1_lags = rep(NA, tma1+1); 
  tar2_lags = rep(NA, tar2); tma2_lags = rep(NA, tma2+1); 
  tar3_lags = rep(NA, tar3); tma3_lags = rep(NA, tma3+1); 
  tar4_lags = rep(NA, tar4); tma4_lags = rep(NA, tma4+1); 
  
  
  # tma2_lags[1] = 0
  # tma3_lags[1] = 0
  
  #........................................
  retardos = c(p_lags,q_lags,P_lags,Q_lags)
  if(d==0 & D==0 & media) retardos = c(retardos,NA)  # Si include.mean = TRUE  compilar
  retardos = c(retardos,
               tar1_lags,tma1_lags,
               tar2_lags,tma2_lags,
               tar3_lags,tma3_lags,
               tar4_lags,tma4_lags)
  
  
  # Modelo SARIMAX - transfer -------------
  
  mod_tr = arimax(y, order = c(p,d,q),include.mean = media,
                  seasonal = list(order = c(P,D,Q),
                                  period = 12),
                  fixed = retardos,
                  # fixed = NULL,
                  xtransf = XblancNmb, transfer = list(c(tar1,tma1),
                                                       c(tar2,tma2),
                                                       c(tar3,tma3),
                                                       c(tar4,tma4))
  )
  
  
  # summary(mod_tr)
  # coeftest(mod_tr)
}

@

\begin{itemize}
\item Precipitación $v^{(1)}$ : $b_1= 0$, $m_1=\Sexpr{tma1}$, $n_1=\Sexpr{tar1}$
\item Temperatura Máxima $v^{(2)}$ : $b_2= 0$, $m_2=\Sexpr{tma2}$, $n_2=\Sexpr{tar2}$
\item Temperatura Mínima $v^{(3)}$ : $b_3= 0$, $m_3=\Sexpr{tma3}$, $n_3=\Sexpr{tar3}$
\item Humedad Relativa $v^{(4)}$ : $b_4= 0$, $m_4=\Sexpr{tma4}$, $n_4=\Sexpr{tar4}$
\end{itemize}


Estimando los coeficientes de este modelo se obtienen los resultados de la tabla \ref{tab:sarimax_estim1}.

<<fig.pos="H">>=
texto = paste0("SARIMAX$(",p,",",d,",",q,")(",P,",",D,",",Q,")$")
tab_model(mod_tr,label_text = "tab:sarimax_estim1",caption_text = texto)

Cff = round(as.numeric(mod_tr$coef),digits = 3)

@





%%%%%%%%%%%%%%%%%%%%%%%%   QUITAR VARIABLES CORRELACIONADAS   %%%%%%%%%%%%%%%%%%%%%%%


\paragraph{Observación.} Como se ve en la tabla \ref{tab:sarimax_estim1} tiene varios de lo coeficientes no significativos, para varios de ellos no es posible estimar numéricamente sus errores estándar, por lo que es necesario, por una parte, quitar aquellas componentes menos significativas.  En esta etapa se hace notoria la necesidad de eliminar variables del modelo, para ello se considera el criterio de quitar aquellas variables exógenas que se encuentren correlacionadas entre si y que no tengan una alta correlación con la variable \textit{output} (Caudal). Para ello se observaron las funciones de correlación cruzada representadas en las figuras \ref{fig:cc_exogenas} y \ref{fig:cc_output} respectivamente.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Quitando la variable Temperatura Máxima y posteriormente Mínima, ya que tampoco tenía coeficientes asociados significativos, se llega al modelo SARIMAX $(1,0,0)(2,1,0)_{12}$, con 3 variables exógenas, cuyas funciones de respuesta al impulso tienen órdenes $(b_k,m_k,n_k)$ como se muestran a continuación:


<<>>=
{
  media = FALSE
  p=1;q=0
  P=2;Q=0
  d=0;D=1
  p_lags = rep(NA, p);q_lags = rep(NA, q)
  P_lags = rep(NA, P);Q_lags = rep(NA, Q)
  
  
  
  #----------------------------------------
  # Ordenes Funciones de Respuesta al Impulso
  tar1 = 8 #Transf - AR
  tma1 = 0 #Transf - MA
  
  tar2 = 0 #Transf - AR
  tma2 = 0 #Transf - MA
  
  tar3 = 0 #Transf - AR
  tma3 = 0  #Transf - MA
  
  tar4 = 3 #Transf - AR
  tma4 = 0  #Transf - MA
  
  tar1_lags = rep(NA, tar1); tma1_lags = rep(NA, tma1+1); 
  tar2_lags = rep(NA, tar2); tma2_lags = rep(NA, tma2+1); 
  tar3_lags = rep(NA, tar3); tma3_lags = rep(NA, tma3+1); 
  tar4_lags = rep(NA, tar4); tma4_lags = rep(NA, tma4+1); 
  
  # tar1_lags[5] = 0
  # tar4_lags[2] = 0
  tma3_lags[1] = 0
  tma2_lags[1] = 0
  #........................................
  retardos = c(p_lags,q_lags,P_lags,Q_lags)
  if(d==0 & D==0 & media) retardos = c(retardos,NA)  # Si include.mean = TRUE  compilar
  retardos = c(retardos,
               tar1_lags,tma1_lags,
               tar2_lags,tma2_lags,
               tar3_lags,tma3_lags,
               tar4_lags,tma4_lags)
  
  
  # Modelo SARIMAX - transfer -------------
  
  mod_tr = arimax(y, order = c(p,d,q),include.mean = media,
                  seasonal = list(order = c(P,D,Q), 
                                  period = 12),
                  fixed = retardos,
                  # fixed = NULL,
                  xtransf = XblancNmb, transfer = list(c(tar1,tma1),
                                                       c(tar2,tma2),
                                                       c(tar3,tma3),
                                                       c(tar4,tma4))
  )
  
  # summary(mod_tr)
  # coeftest(mod_tr)
}


@




\begin{itemize}
\item Precipitación $v^{(1)}$ : $b_1= 0$, $m_1=\Sexpr{tma1}$, $n_1=\Sexpr{tar1}$
% \item Temperatura Máxima $v^{(2)}$ : $b_2= 0, $m_2=\Sexpr{tma2}$, $n_2=\Sexpr{tar2}$
% \item Temperatura Mínima $v^{(3)}$ : $b_3= 0, $m_3=\Sexpr{tma3}$, $n_3=\Sexpr{tar3}$
\item Humedad Relativa $v^{(4)}$ : $b_4= 0$, $m_4=\Sexpr{tma4}$, $n_4=\Sexpr{tar4}$
\end{itemize}


Estimando los coeficientes de este modelo se obtienen los resultados de la tabla \ref{tab:sarimax_estim2}. Como se puede observar, para este modelo se obtiene que todos los coeficientes son significativos. 


<<fig.pos="H">>=
texto = paste0("SARIMAX$(",p,",",d,",",q,")(",P,",",D,",",Q,")$")
tab_model(mod_tr,label_text = "tab:sarimax_estim2",caption_text = texto)
Cff = round(as.numeric(mod_tr$coef),digits = 3)
@

Sin embargo, al analizar sus residuos (ver figura \ref{fig:sarima_estim2}), se ve que los P-valores del estadístico de Ljung-Box son menores a 0.05, por lo tanto se considera que la autocorrelación de los residuos es significativa, y se rechaza su independencia.

<<fig.pos= "h",fig.height=8,fig.cap="\\label{fig:sarima_estim2} Residuos - Test Portmanteau (Ljung-Box) SARIMAX $(1,0,0)(2,1,0)_{12}$">>=
tsdiag(mod_tr,gof.lag = 36)
@




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Tras probar varias combinaciones de parámetros y con la ayuda de las funciones de aucorrelación, se puede corregir las partes SARMA del modelo,y de las funciones de correlación cruzada entre los residuos y $x_t^{k}$ para corregir las funciones de respuesta al impulso, se llega al modelo SARIMAX $(1,0,0)(2,1,0)_{12}$, cuyas funciones de respuesta al impulso tienen órdenes $(b_k,m_k,n_k)$ como se muestran a continuación:



<<>>=
{
  media = FALSE
  p=1;q=0
  P=2;Q=0
  d=0;D=1
  p_lags = rep(NA, p);q_lags = rep(NA, q)
  P_lags = rep(NA, P);Q_lags = rep(NA, Q)
  
  { # Modelo Estable :)  -----------------
    tar1 = 3 #Transf - AR
    tma1 = 0 #Transf - MA
    
    tar2 = 0 #Transf - AR
    tma2 = 0 #Transf - MA
    
    tar3 = 0 #Transf - AR
    tma3 = 0  #Transf - MA
    
    tar4 = 0 #Transf - AR
    tma4 = 0  #Transf - MA
  }
  
  
  #----------------------------------------
  # Ordenes Funciones de Respuesta al Impulso
  tar1 = 2 #Transf - AR
  tma1 = 0 #Transf - MA
  
  tar2 = 0 #Transf - AR
  tma2 = 0 #Transf - MA
  
  tar3 = 0 #Transf - AR
  tma3 = 0  #Transf - MA
  
  tar4 = 2 #Transf - AR
  tma4 = 0  #Transf - MA
  
  tar1_lags = rep(NA, tar1); tma1_lags = rep(NA, tma1+1); 
  tar2_lags = rep(NA, tar2); tma2_lags = rep(NA, tma2+1); 
  tar3_lags = rep(NA, tar3); tma3_lags = rep(NA, tma3+1); 
  tar4_lags = rep(NA, tar4); tma4_lags = rep(NA, tma4+1); 
  
  # tar1_lags[5] = 0
  # tar4_lags[2] = 0
  tma3_lags[1] = 0
  tma2_lags[1] = 0
  tar4_lags[1] = 0
  #........................................
  retardos = c(p_lags,q_lags,P_lags,Q_lags)
  if(d==0 & D==0 & media) retardos = c(retardos,NA)  # Si include.mean = TRUE  compilar
  retardos = c(retardos,
               tar1_lags,tma1_lags,
               tar2_lags,tma2_lags,
               tar3_lags,tma3_lags,
               tar4_lags,tma4_lags)
  
  
  # Modelo SARIMAX - transfer -------------
  
  mod_tr = arimax(y, order = c(p,d,q),include.mean = media,
                  seasonal = list(order = c(P,D,Q), 
                                  period = 12),
                  fixed = retardos,
                  # fixed = NULL,
                  xtransf = XblancNmb, transfer = list(c(tar1,tma1),
                                                       c(tar2,tma2),
                                                       c(tar3,tma3),
                                                       c(tar4,tma4))
  )
  
  # summary(mod_tr)
  # coeftest(mod_tr)
}

# tsdiag(mod_tr,gof.lag = 36)
@




\begin{itemize}
\item Precipitación $v^{(1)}$ : $b_1= 0$, $m_1=\Sexpr{tma1}$, $n_1=\Sexpr{tar1}$
% \item Temperatura Máxima $v^{(2)}$ : $b_2= 0, $m_2=\Sexpr{tma2}$, $n_2=\Sexpr{tar2}$
% \item Temperatura Mínima $v^{(3)}$ : $b_3= 0, $m_3=\Sexpr{tma3}$, $n_3=\Sexpr{tar3}$
\item Humedad Relativa $v^{(4)}$ : $b_4= 0$, $m_4=\Sexpr{tma4}$, $n_4=\Sexpr{tar4}$
\end{itemize}


Estimando los coeficientes de este modelo se obtienen los resultados de la tabla \ref{tab:sarimax_estim3}. Como se puede observar, para este modelo se tienen todos los coeficientes significativos. 


<<fig.pos="H">>=
texto = paste0("SARIMAX$(",p,",",d,",",q,")(",P,",",D,",",Q,")$")
tab_model(mod_tr,label_text = "tab:sarimax_estim3",caption_text = texto)
Cff = round(as.numeric(mod_tr$coef),digits = 3)
@



Y tras analizar los residuos asociados a este modelo (ver figura \ref{fig:sarimax_estim3}), se tiene que los P-valores del estadístico de Ljung-Box son mayores que 0.05, por lo que se puede aceptar que sus residuos son independientes. Así, este es el modelo que representará el Clúster 1. Se puede representar este modelo mediante la siguiente ecuación:


\begin{eqnarray} \label{eq:sarimax}
\Delta_{12} Y_t = \frac{0.148 }{1+ 1.764B + 0.948B^2} \Delta_{12} X^{(1)}_t + \frac{-7.326 }{1 - 0.749B^2} \Delta_{12} X^{(4)}_t     \nonumber\\
+ \frac{1}{( 1 - 0.554 B )(1+ 0.719 B^{12} +0.387 B^{24} )  }\varepsilon_t                  \label{prime}
\end{eqnarray}


<<fig.pos= "h",fig.height=8,fig.cap="\\label{fig:sarimax_estim3} Residuos - Test Portmanteau (Ljung-Box) SARIMAX $(1,0,0)(2,1,0)_{12}$">>=
tsdiag(mod_tr,gof.lag = 36)
@



En la siguiente sección se hace una breve reseña del uso de la aplicación web creada para facilitar la ejecución de la metodología ya descrita.

Mientras que en la sección (\autoref{chap:resultados}) se muestran a detalle los resultados de modelar todas las series que componen el clúster 1, partiendo de un modelo con los mismos parámetros (aunque no los mismos coeficientes), así mismo se muestran las predicciones e intervalos de confianza obtenidas de los modelos SARIMA y SARIMAX correspondientes.














%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

