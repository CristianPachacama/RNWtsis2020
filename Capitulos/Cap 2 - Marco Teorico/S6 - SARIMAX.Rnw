\section{Modelamiento de Series de Tiempo}

El análisis de los datos experimentales asociados a series temporales conduce a nuevos problemas en el modelamiento estadístico y la inferencia. La evidente correlación existente entre observaciones adyacentes en el tiempo puede restringir severamente la aplicabilidad de muchos de los métodos estadísticos convencionales, que dependen de la suposición de que las observaciones son independientes e idénticamente distribuidas \cite{shumway2017time}.
%El enfoque sistemático mediante el cual se responde a las preguntas matemáticas y estadísticas planteadas por estas correlaciones de tiempo se conoce como análisis de series de tiempo \cite{shumway2017time}.
En esta sección daremos un enfoque sistemático que nos permitirá resolver desde la matemática y estadística los problemas antes descritos, con el objetivo de modelar series de tiempo, en particular las asociadas a caudales, que pueden presentar peculiaridades como la estacionalidad, que dificultan su análisis.
%
%Una herramienta fundamental que permite la especificación de los parámetros de este tipo de modelos es la llamada función de autocorrelación así como la autocorrelación parcial, que como veremos juega un rol trasendental en elección de la métrica usada en la etapa de clusterización.





\subsection{Metodología Box y Jenkins}
\label{sec2box}

Llamada así en honor a sus creadores \citeauthor{box1970time}, es hasta la actualidad la metodología más utilizada para identificar, estimar, verificar y predecir a partir de un modelo ARIMA (Autoregressive Integrated Moving Average). 


% ARIMA  ------------------------
\begin{definicion}
Un proceso $(Y_t, t \in \Z)$ de segundo orden se llama $ARIMA(p,d,q)$ si puede representarse mediante la ecuación:

\begin{equation}
\phi  (B) \Delta^d Y_t =  \theta  (B) \varepsilon_t\label{eq:arima_def}
\end{equation}

Donde, $\phi(z)$ y $\theta (z)$ son polinomios de grado $p$ y $q$ respectivamente, y que tienen raíces fuera del círculo unitario complejo.
\end{definicion}

En ese caso se dirá también que $(Y_t, t \in \Z)$ responde a un modelo $ARIMA(p,d,q)$. Notemos además que en la ecuación \ref{eq:arima_def} se pueden identificar las siguientes componentes:

\begin{itemize}
\item $B$ es el operador de retardos,
\item $\phi(B)$ es el polinomio AR (Autoregresivo) de orden $p$,
\item $\theta  (B)$ es el polinomio MA (Media Móvil) de orden $q$,
\item $\Delta^d:=(1-B)^d$ es el operador de diferenciación de orden $d$,
\item $(\varepsilon_t)$ es un ruido blanco de varianza $\sigma^2$.
\end{itemize}



A partir de trabajos como los de \citeauthor{chatfield1996,capa2016seriest}, resumimos la metodología Box y Jenkins, para el modelamiento de esta clase de procesos, en las siguientes etapas:


\begin{enumerate}
% Chatfield 1996
\item \textit{Identificación a Priori.} Consiste de examinar los datos para ver que miembro (o miembros) de la clase de procesos ARIMA(p,d,q) es el más adecuado, esto a partir de las observaciones de la serie de tiempo con las que contamos. Es decir, en esta etapa buscamos los posibles valores para la tripleta (p,d,q), en general, no obtenemos una sola tripleta de valores, cabe mencionar que en esta etapa juegan un rol fundamental las funciones de Autocorrelación y Autocorrelación Parcial, pues nos permiten determinar posibles valores de la tripleta.

\item \textit{Estimación.} En este punto se estiman los parámetros de los modelos escogidos, es decir, se estiman los coeficientes de los polinomios asociados a la parte autoregresiva (polinomios de orden $p$) y los de las parte media móvil (polinomios de orden $q$) del proceso.

\item \textit{Validación.} Consiste de verificar las hipótesis realizadas en los modelos estimados en las dos etapas previas. Es decir, realizar pruebas estadísticas para la significancia de los coeficientes estimados, además, analizar de los residuos y verificar que se comporta como ruido blanco. Cabe mencionar que luego de esta etapa podríamos rechazar varios modelos, e inclusive todos, en tal caso es necesario plantearse más modelos (recordemos que basta elegir una tripleta $p,d,q$ adecuadamente) hasta encontrar al menos uno que pase esta etapa.

\item \textit{Identificación a Posteriori.} En esta etapa elegimos el ``mejor" modelo, para ello consideramos dos criterios principalmente, el primero es considerar el modelo de mayor poder predictivo, el otro es  tomar el de mayor cantidad de ``información".

\item \textit{Predicción.} Una vez escogido el mejor modelo se procede a realizar la predicción de los valores de la serie para un tiempo futuro (posterior) al periodo de tiempo considerado en la estimación del modelo.


\end{enumerate}


\paragraph{Nota.}
Recordemos que las series que se pretenden modelar en este estudio son series asociadas a caudales de ríos, que se conoce tienen un comportamiento estacional, es decir, los datos de caudal correspondientes a un mismo mes de diferentes años tienen tendencia a situarse de manera similar respecto a la media anual. Esto hace pensar en incluir en el modelo ARIMA retardos que son múltiplos de 12, sin embargo, su cálculo se convertiría en una tarea muy pesada y sujeta a varios errores. Para evitar este aumento drástico de parámetros, \citeauthor{box2015time} propusieron una extensión de los modelos ARIMA que consideren la componente estacional de la serie, conocidos como modelos SARIMA.


% SARIMA  --------------------------
\begin{definicion}
Diremos que un proceso $(Y_t)$ de segundo orden,  responde a un modelo SARIMA$(p,d,q)(P,D,Q)_s$ si puede representarse mediante la ecuación:

\begin{equation}
\phi  (B)\Delta^d \Phi (B^s) \Delta _s^DY_t = \theta  (B) \Theta (B^s)\varepsilon_t
\label{eq:sarima_def}
\end{equation}
Donde, $\phi (z)$, $\theta (z)$, $\Phi (z)$ y $\Theta (z)$ son polinomios con raíces fuera del círculo unitario complejo.

\end{definicion}

Cabe mencionar que podemos usar esta metodología Box y Jenkins también en los procesos SARIMA, considerando que en las etapas de identificación es necesario escoger en lugar tripletas, arreglos de 7 parámetros $(p,d,q,s,P,D,Q)$. 
Los 4 parámetros extras corresponden a los ordenes de los polinomios asociados a la parte estacional del modelo: 

\begin{itemize}
\item $\Phi $ es un polinomio de grado $P$,
\item $\Theta $ es un polinomio de grado $Q$,
\item $\Delta _s^D:=(1-B^s)^D$ es el operador de diferenciación estacional de orden $D$,y $s$ es el periodo de la estacionalidad.  Por ejemplo, $s=12$ para datos mensuales de estacionalidad anual.
\end{itemize}


\subsection{Función de transferencia}

Un modelo que relacione una serie temporal $(Y_t)$ (conocida como \textit{output}) con otra serie (o series) $(X_t)$ (conocida como \textit{input})a modo de variable explicativa (exógena), se conoce como \textit{función de transferencia}. Es decir, si podemos escribir $Y_t$ de la forma:

$$Y_t= f(X_t)$$

Por ejemplo, el caso más sencillo puede ser, considerar a la regresión simple, es decir:

$$Y_t = c + v_0X_t + N_t$$

Sin embargo, una relación de este tipo podría ocasionar una serie de problemas como:
\begin{itemize}
\item Acción de la serie $Y_t$ (output) sobre las series input, en lugar de que las series input afecten a la serie output.
\item Se omitido los términos retardos de la variable (o variables) inputs.
\item Residuos autocorrelacionados.
\item Patrones de autocorrelación comunes compartidos por $Y_t$ y $X_t$ que pueden producir \textit{correlación espuria}.
\end{itemize}

Pues bien, como vemos relaciones como las antes planteadas conllevan a una serie de problemas, pero con unas adecuaciones pueden sobrellevarse, como se muestra a continuación:

\begin{equation} \label{eq:fun_transfer}
\begin{split}
Y_t & = v(B)X_t \\
&  =  (v_0+v_1B+v_2B^2+\dots )B^b X_t + N_t \\
&  = \frac{\omega_0-\omega_1B- \dots -\omega_n B^n}{1-\delta_1-\dots -\delta_m B^m} B^b X_t + N_t \\
& = \frac{\omega(B)}{\delta(B)}B^b X_t + N_t
\end{split}
\end{equation}

Esta corresponde a la representación genérica del modelo de función de transferencia con un input. Donde, $(Y_t)$ y $(X_t)$ se suponen estacionarios,  $(N_t)$ se conoce como \textit{perturbación}, y $v(B)$ como \textit{función de respuesta al impulso}, ya que sus coeficientes describen el efecto sobre el output $(Y_t)$ que provocaría un impulso en el input $(X_t)$ . Este tipo de relación posee varias ventajas, como son:

\begin{itemize}
\item Permite una representación \textit{parsimoniosa}, es decir, con un número reducido de coeficientes.
\item Posee una estrategia sencilla para la especificación del modelo dinámico, que captura adecuadamente la relación input sobre output.
\item Se cuenta con instrumentos para corroborar que se utilizan inputs y outputs que poseen características análogas de estacionariedad, por lo que los residuos del modelo son estacionarios.
\end{itemize} 

Existe una variedad de alternativas para las funciones de transferencia, otras opciones como considerar una relación no lineal entre el output y el input, o considerar procesos a tiempo continuo, entre otras. Varias de ellas se detallan en \cite[Capitulo~5]{box2015time}, mientras que las distintas variantes , por ejemplo considerando que el input y output no son estacionarios, se analizan a detalle en \cite{pankratz2012forecasting}.



\subsection{Modelo SARIMAX}
El modelo SARIMAX (Seasonal Autoregressive Integrated Moving Average with exogenous variables), es una extensión del modelo SARIMA, que además de considerar la parte estacional de las series de tiempo, integra variables exógenas para aumentar su capacidad explicativa y predictiva. 

\begin{definicion}
Un proceso $(Y_t, t\in\Z)$ de segundo orden,  responde a un modelo SARIMAX$(p,d,q)(P,D,Q)_s(b,m,n)$, si puede representarse mediante la ecuación:

\begin{equation} \label{eq:sarimax_def}
Y_t = v(B) X_t  + N_t
\end{equation}

$$\Delta_s^D  \Delta^d N_t := \frac{\theta(B) \Theta (B^s)}{\phi(B)\Phi (B^s)}\varepsilon_t$$

Donde, $\phi (z)$, $\theta (z)$, $\Phi (z)$ y $\Theta (z)$ son polinomios con raíces fuera del círculo unitario complejo. Además se tiene:

$$v (B):= \frac{\omega (B)}{\delta (B)} B^{b}$$

Donde $\omega(z) $ es un polinomio de grado $n$, $\delta(z) $ un polinomio de grado $m$. 


\end{definicion}

Y además:

\begin{itemize}
\item $X_t $ es la variable exógena (regresora),
\item $v(B)$ es la función de respuesta al impulso, asociada a $X_t$
\item El coeficiente $b$ se conoce como \textit{tiempo muerto}.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Metodología Box y Jenkins para el modelo SARIMAX}
\label{sec:metod_sarimax}
Para la identificación del modelo SARIMAX se hace una extensión de la metodología Box y Jenkins para modelos ARIMA antes expuesta, añadiendo una etapa dedicada a la identificación de la función de transferencia, la aplicación y ejemplos de esta metodología se encuentra detallada en \citeauthor{novales1993econometria} \citeyear{novales1993econometria}. Resumimos el proceso en las siguientes etapas:

\begin{enumerate}
\item Filtrar tanto $(Y_t)$ como $(X_t)$, para $k=1,2,...,K$ para que todas sean estacionarias. Es decir, identificar los parámetros de diferenciación $d$ y $D$, luego calcular las series: 


$$y_t=\Delta^d \Delta_s^D Y_t $$
$$x_t=\Delta^{d'} \Delta_s^{D'} X_t $$

Este proceso se conoce como \textit{preblanqueo}. La ventaja de este proceso es que ahora podemos plantear la relación entre procesos estacionarios siguiente:


\begin{equation}\label{eq:transf_y}
y_t = v(B)x_t + n_t
\end{equation}


\item Como $x_t$ es estacionario, hallar un modelo SARMA adecuado para esta serie, es decir:

$$\frac{ \phi_x(B) \Phi_x(B) }{\theta_x(B) \Theta_x(B)} x_t= \alpha_t $$

Donde $\alpha_t$ es un r.b. de varianza $\sigma_{\alpha}^2$


\item Aplicar el modelo hallado en el anterior paso a $y_t$, es decir:

$$\beta_t = \frac{ \phi_x(B) \Phi_x(B)}{\theta_x(B) \Theta_x(B)} y_t$$

Notemos que de la relación anterior, es posible que $\beta_t$ no sea un r.b. Luego, es claro que:

$$\beta_t = \frac{ \phi_x(B) \Phi_x(B)}{\theta_x(B) \Theta_x(B)} v(B) x_t + \frac{ \phi_x(B) \Phi_x(B)}{\theta_x(B) \Theta_x(B)} n_t $$

\begin{equation}\label{eq:transf_bet}
\Longrightarrow  \beta_t = v(B) \alpha_t + \varepsilon_t
\end{equation}

Si multiplicamos a esta última relación $\alpha_{t-j}$, suponemos que $\varepsilon_t$ es un ruido blanco, y sacamos la esperanza a ambos lados, se obtiene:

$$\gamma_{\alpha\beta}(j) = v_j \sigma_\alpha^2$$

$$\Longrightarrow  v_j = \rho_{\alpha\beta}(j)\frac{\sigma_\beta}{\sigma_\alpha}$$

Donde $v_j$ son los coeficientes de $v(B)$ como se ve en \ref{eq:fun_transfer}. Es decir, existe una relación directa entre $v_j$ y la función de correlación cruzada de las series $\alpha_t$ y $\beta_t$, por lo que podemos tener una aproximación, no muy buena, pero que nos permitirá conocer los órdenes de los polinomios $\delta(B)$ y $\omega(B)$ que componen $v(B)$. Para ello, hay que considerar lo siguiente: 

$$(1-\delta_1B-\dots,-\delta_mB^m) (v_0+v_1B+v_2B^2\dots)= (\omega_0-\omega_1B-\dots,-\omega_n^B^n)B^b$$

\begin{equation} 
%\label{eq:fun_transfer}
\begin{split}
v_j & = 0  \text{ \phantom{aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa} para } j<b\\
v_j & = \delta_1v_{j-1}+\detla_2 v_{j-2} + \dots +\delta_m v_{j-m} + \omega_0  \text{ \phantom{aaaaaa} para } j=b\\
v_j & = \delta_1v_{j-1}+\detla_2 v_{j-2} + \dots +\delta_m v_{j-m} - \omega_{j-b}  \text{ \phantom{aaaa.} para } b < j\leq b+n\\
v_j & = \delta_1v_{j-1}+\detla_2 v_{j-2} + \dots +\delta_m v_{j-m}  \text{ \phantom{aaaaaaaaaaa} para } j>b+n\\
\end{split}
\end{equation}
De las ecuaciones anteriores se concluye lo siguiente:
\begin{enumerate}
\item Los $b$ primeros coeficientes de $v(B)$ son nulos y corresponden al tiempo muerto.
\item Los coeficientes desde $v_b$ hasta $v_{b+n}$ no siguen ningun patrón en particular.
\item Los coeficientes de $v_{b+n+1}$ en adelante siguen una ecuación en diferencias de órden $m$, con $m$ valores iniciales $v_j$ para $b+n\leq j\leq b+n-m+1$

\end{enumerate}

\item Identificada la función de transferencia, es necesario encontrar la estructura SARMA que falta identificar del modelo SARIMAX, para ello consideramos dos factores. El primero de ellos, es considerar que para llegar a la relación \ref{eq:transf_bet}, partimos del supuesto de que:

\begin{equation}\label{eq:nt_eps}
 \frac{ \phi_x(B) \Phi_x(B)}{\theta_x(B) \Theta_x(B)} n_t = \varepsilon_t 
\end{equation}

Que como vemos tiene relación directa con $N_t$ debido a la ecuación \ref{eq:sarimax_def}. Por lo tanto, en la identificación de la estructura SARMA debemos considerar la estructura ya hallada en el paso 2, es decir, incluir en el modelo final, las partes autoregresivas y medias móviles (inclusive estacionales) de \ref{eq:nt_eps}.

Por otra parte, un segundo factor a considerar es que la perturbación es desconocida a priori, por lo que debemos plantear un modelo para la perturbación aproximada $n_t^{*}$, que definimos como:
$$n_t^{*} = y_t - v^{*}(B)x_t$$
Donde:
$$v^{*}(B):=\frac{ \phi_x(B) \Phi_x(B) }{\theta_x(B) \Theta_x(B)}$$
Por lo tanto la relación anterior se reescribe como:
$$n_t^{*} = y_t -\alpha_t$$
Es decir, calculamos $n_t^{*}$, y luego buscamos un modelo SARMA, para esta serie, es decir, con polinomios estacionales, pero sin diferencias. 

Luego la estructura para el modelo final consistira de las estructuras SARMA de $n_t^{*}$ como la hallada en el paso 3, es decir, los polinomios de retardos de la ecuación \ref{eq:nt_eps}.

\item Identificados tanto la función de transferencia asociada a $x_t$, como el modelo SARMA de $n_t$, el siguiente paso es validar el modelo y de ser necesario corregirlo. Para que el modelo sea aceptado, los residuos $\varepsilon_t$ deberían comportarse como un ruido blanco, es decir, su función de autocorrelación debe ser estadísticamente nula. De igual manera la función de correlación cruzada entre $\varepsilon_t$ y $\alpha_t$ (o equivalentemente con $x_t$), no debe ser significativamente distinta de cero. Para lo cual, hay que considerar que los intervalos de confianza para la correlación cruzada en general vienen dados por:

$$IC(\rho_{\varepsilon\alpha}(j) ) \approx \pm 1.96 \sqrt{ \frac{1+\sum_{h=1}^k \hat\rho_\varepsilon(h) \hat\rho_\alpha(h) }{T-j} } $$

Donde $T$ es el número de observaciones con las que se estimaron las funciones de autocorrelación.

De igual manera las correcciones se realizan en función de lo observado en las funciones de autocorrelación de los residuos, esto para corregir la estructura SARMA del modelo. Por otro lado, para corregir la función de respuesta al impulso $v(B)$ se analiza la correlación cruzada entre los residuos $\varepsilon_t$ y los $x_t$, que se puede probar, mide la discrepancia entre el modelo real versus el modelo planteado.

\end{enumerate}


\paragraph{Observación.} Un caso más general del modelo SARIMAX antes expuesto, es considerar más de una variable exógena, autores como \citeauthor{pankratz2012forecasting} \citeyear{pankratz2012forecasting} abordan ampliamente el problema de identificación de esta clase de modelos, que resulta análoga a la metodología aquí expuesta. También desarrolla un análisis detallado de las funciones de respuesta al impulso, los patrones que siguen los coeficientes $v_j$ gráficamente, según el órden de los polinomios que los componen.
